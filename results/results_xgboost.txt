2025-04-15 09:07:20,611 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3}

=== Processing XGBoost ===
Tuning XGBoost hyperparameters...
pyswarms.single.global_best: 100%|██████████|10/10, best_cost=-0.907
2025-04-15 09:12:30,129 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.9068439254841705, best pos: [0.28401961 7.8029476  6.17243871 0.98841606 0.88788678 0.32766076]

Optimized XGBoost Parameters:
{'learning_rate': np.float64(0.28401960527716236), 'max_depth': 7, 'min_child_weight': np.float64(6.172438714409442), 'subsample': np.float64(0.9884160626446158), 'colsample_bytree': np.float64(0.8878867794274299), 'gamma': np.float64(0.3276607618022003)}
Best ROC-AUC: 0.9068
Training XGBoost with optimized parameters...
XGBoost Results:
ROC-AUC: 0.9175
PR-AUC: 0.5607
Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.83      0.91    113866
         1.0       0.16      0.85      0.27      4242

    accuracy                           0.83    118108
   macro avg       0.58      0.84      0.59    118108
weighted avg       0.96      0.83      0.88    118108