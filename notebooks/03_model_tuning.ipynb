{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c88c3804",
      "metadata": {
        "id": "c88c3804"
      },
      "source": [
        "# Hyperparameter Tuning Using PSO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e65d70",
      "metadata": {
        "id": "b2e65d70"
      },
      "source": [
        "#### In this notebook, we present the implementation of the hyperparameter search using particle swarm optimization (PSO). After the best hyperparameters for each model are found, training and evaluation are performed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "725b3dbe",
      "metadata": {
        "id": "725b3dbe"
      },
      "source": [
        "Install necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3ac7738b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ac7738b",
        "outputId": "c27af57f-a1be-48c6-f39f-16dcdde10c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 3)) (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 6)) (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r ../req.txt (line 8)) (2.18.0)\n",
            "Collecting scikeras (from -r ../req.txt (line 9))\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting deap (from -r ../req.txt (line 10))\n",
            "  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting pyswarms (from -r ../req.txt (line 11))\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r ../req.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r ../req.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r ../req.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r ../req.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r ../req.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r ../req.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r ../req.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r ../req.txt (line 8)) (0.37.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms->-r ../req.txt (line 11)) (25.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms->-r ../req.txt (line 11)) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms->-r ../req.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms->-r ../req.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r ../req.txt (line 8)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r ../req.txt (line 8)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r ../req.txt (line 8)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r ../req.txt (line 8)) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r ../req.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r ../req.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r ../req.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r ../req.txt (line 8)) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r ../req.txt (line 8)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r ../req.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r ../req.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r ../req.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r ../req.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r ../req.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r ../req.txt (line 8)) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap, pyswarms, scikeras\n",
            "Successfully installed deap-1.4.2 pyswarms-1.3.0 scikeras-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ../req.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8769d520",
      "metadata": {
        "id": "8769d520"
      },
      "source": [
        "Start with the existing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "89f7ed52",
      "metadata": {
        "id": "89f7ed52"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "from pyswarms.single import GlobalBestPSO\n",
        "from functools import partial\n",
        "from typing import Dict, List, Tuple, Union, Optional\n",
        "\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "class ModelPipeline:\n",
        "    \"\"\"\n",
        "    A flexible, modular pipeline for feature selection,\n",
        "    models tuning, and training.\n",
        "\n",
        "    Attributes:\n",
        "        data_path (str): path to the dataset (Pandas parquet)\n",
        "        sample_frac (float): part of a dataset used for training\n",
        "        X (np.array): feature vectors\n",
        "        Y (np.array): labels\n",
        "        selected_features (List[str]): list of selected features\n",
        "        scaler ()\n",
        "        X_train, X_test, y_train, y_test (np.array's): train and test dataset splits\n",
        "        models (List[Dict]): list of dictionaries describing models\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_path: str, selected_features=None, sample_frac: float = 1.0):\n",
        "        \"\"\"Initialize the pipeline with data loading\"\"\"\n",
        "        self.data_path = data_path\n",
        "        self.sample_frac = sample_frac\n",
        "        self.selected_features = selected_features\n",
        "        self._load_data()\n",
        "        self.scaler = None\n",
        "        self.models = {\n",
        "            'RandomForest': {\n",
        "                'tune_func': self.tune_random_forest,\n",
        "                'train_func': self.train_random_forest,\n",
        "                'params': None\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'tune_func': self.tune_xgboost,\n",
        "                'train_func': self.train_xgboost,\n",
        "                'params': None\n",
        "            },\n",
        "            'LightGBM': {\n",
        "                'tune_func': self.tune_lightgbm,\n",
        "                'train_func': self.train_lightgbm,\n",
        "                'params': None\n",
        "            },\n",
        "            'DenseNN': {\n",
        "                'tune_func': self.tune_dense_nn,\n",
        "                'train_func': self.train_dense_nn,\n",
        "                'params': None\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _random_undersample(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "        \"\"\"Undersample dataset for binary labels\"\"\"\n",
        "        a_label, b_label = y.unique()\n",
        "        a_label_cnt, b_label_cnt = y.value_counts()\n",
        "        minority_label = a_label if (a_label_cnt < b_label_cnt) else b_label\n",
        "        majority_label = b_label if (a_label_cnt < b_label_cnt) else a_label\n",
        "        minority_cnt = a_label_cnt if (a_label_cnt < b_label_cnt) else b_label_cnt\n",
        "\n",
        "        # Select all elements with minority label\n",
        "        minority_y = y[y == minority_label]\n",
        "        new_X = X.loc[minority_y.index]\n",
        "        new_y = minority_y\n",
        "\n",
        "        # Sample elements with majority label\n",
        "        majority_y = y[y == majority_label]\n",
        "        sampled_majority = majority_y.sample(n=minority_cnt, random_state=42)\n",
        "        new_X = pd.concat([new_X, X.loc[sampled_majority.index]])\n",
        "        new_y = pd.concat([new_y, sampled_majority])\n",
        "\n",
        "        return new_X, new_y\n",
        "\n",
        "    def _load_data(self) -> None:\n",
        "        \"\"\"Load and prepare data\"\"\"\n",
        "        X = pd.read_parquet(self.data_path)\n",
        "        y = X['remainder__isFraud']\n",
        "        X = X.drop(columns=['remainder__isFraud'])\n",
        "\n",
        "        \"\"\"Prepare train/test split and optionally select features\"\"\"\n",
        "        if self.selected_features is not None:\n",
        "            X = X.iloc[:, self.selected_features]\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        # Data split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Undersampling for equal proportion of labels\n",
        "        self.X_train, self.y_train = self._random_undersample(X_train, y_train)\n",
        "        self.X_test, self.y_test = X_test, y_test\n",
        "\n",
        "        # Take a sample using sample_frac\n",
        "        if self.sample_frac < 1.0:\n",
        "            self.X_train = self.X_train.sample(frac=self.sample_frac, random_state=42)\n",
        "            self.y_train = self.y_train.loc[self.X_train.index]\n",
        "\n",
        "    def evaluate_features(self, individual, X_train, y_train, X_val, y_val) -> Tuple[float]:\n",
        "        \"\"\"Evaluate fitness of feature subset using RandomForest\"\"\"\n",
        "        selected = [i for i, val in enumerate(individual) if val == 1]\n",
        "\n",
        "        if not selected:  # At least one feature must be selected\n",
        "            return 0.0,\n",
        "\n",
        "        X_train_sub = X_train.iloc[:, selected]\n",
        "        X_val_sub = X_val.iloc[:, selected]\n",
        "\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=50,\n",
        "            max_depth=5,\n",
        "            class_weight='balanced_subsample',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "        model.fit(X_train_sub, y_train)\n",
        "        y_proba = model.predict_proba(X_val_sub)[:, 1]\n",
        "        score = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "        # Add penalty for too many features\n",
        "        feature_penalty = len(selected) / X_train.shape[1] * 0.1\n",
        "        return score - feature_penalty,\n",
        "\n",
        "    def genetic_feature_selection(self, n_pop: int = 50, n_gen: int = 20,\n",
        "                                  cxpb: float = 0.5, mutpb: float = 0.2) -> List[int]:\n",
        "        \"\"\"Perform feature selection using Genetic Algorithm\"\"\"\n",
        "        # Split data for feature selection\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            self.X, self.y, test_size=0.2, stratify=self.y, random_state=42\n",
        "        )\n",
        "\n",
        "        # DEAP setup\n",
        "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "        toolbox = base.Toolbox()\n",
        "        toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "        toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
        "                         toolbox.attr_bool, n=self.X.shape[1])\n",
        "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "        eval_fn = partial(self.evaluate_features,\n",
        "                          X_train=X_train, y_train=y_train,\n",
        "                          X_val=X_val, y_val=y_val)\n",
        "        toolbox.register(\"evaluate\", eval_fn)\n",
        "        toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "        toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "        toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "        # Run GA\n",
        "        pop = toolbox.population(n=n_pop)\n",
        "        hof = tools.HallOfFame(1)\n",
        "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "        stats.register(\"avg\", np.mean)\n",
        "        stats.register(\"min\", np.min)\n",
        "        stats.register(\"max\", np.max)\n",
        "\n",
        "        pop, log = algorithms.eaSimple(\n",
        "            pop, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=n_gen,\n",
        "            stats=stats, halloffame=hof, verbose=True\n",
        "        )\n",
        "\n",
        "        best_individual = hof[0]\n",
        "        selected_features = [i for i, val in enumerate(best_individual) if val == 1]\n",
        "\n",
        "        print(f\"\\nSelected {len(selected_features)} features out of {self.X.shape[1]}\")\n",
        "        print(\"Selected feature indices:\", selected_features)\n",
        "\n",
        "        self.selected_features = selected_features\n",
        "        return selected_features\n",
        "\n",
        "    # ==================== Random Forest ====================\n",
        "    def tune_random_forest(self, n_particles: int = 5, iters: int = 10) -> Dict[str, float]:\n",
        "        \"\"\"PSO optimization for Random Forest hyperparameters\"\"\"\n",
        "\n",
        "        bounds = (\n",
        "            np.array([50, 2, 2, 1]),    # min values\n",
        "            np.array([500, 30, 10, 30])  # max values\n",
        "        )\n",
        "\n",
        "        def objective_function(params):\n",
        "            scores = []\n",
        "            for param_set in params:\n",
        "                n_estimators = int(param_set[0])\n",
        "                max_depth = int(param_set[1])\n",
        "                min_samples_split = int(param_set[2])\n",
        "                max_features = min(int(param_set[3]), self.X_train.shape[1])\n",
        "\n",
        "                model = RandomForestClassifier(\n",
        "                    n_estimators=n_estimators,\n",
        "                    max_depth=max_depth,\n",
        "                    min_samples_split=min_samples_split,\n",
        "                    max_features=max_features,\n",
        "                    class_weight='balanced_subsample',\n",
        "                    n_jobs=-1,\n",
        "                    random_state=42\n",
        "                )\n",
        "\n",
        "                cv_scores = []\n",
        "                cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "                for train_idx, val_idx in cv.split(self.X_train, self.y_train):\n",
        "                    X_train_cv, X_val_cv = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]\n",
        "                    y_train_cv, y_val_cv = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n",
        "\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    y_proba = model.predict_proba(X_val_cv)[:, 1]\n",
        "                    score = roc_auc_score(y_val_cv, y_proba)\n",
        "                    cv_scores.append(score)\n",
        "\n",
        "                scores.append(-np.mean(cv_scores))\n",
        "\n",
        "            return np.array(scores)\n",
        "\n",
        "        optimizer = GlobalBestPSO(\n",
        "            n_particles=n_particles,\n",
        "            dimensions=len(bounds[0]),\n",
        "            options={'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3},\n",
        "            bounds=bounds\n",
        "        )\n",
        "\n",
        "        best_cost, best_params = optimizer.optimize(objective_function, iters=iters)\n",
        "\n",
        "        optimized_params = {\n",
        "            'n_estimators': int(best_params[0]),\n",
        "            'max_depth': int(best_params[1]),\n",
        "            'min_samples_split': int(best_params[2]),\n",
        "            'max_features': int(best_params[3])\n",
        "        }\n",
        "\n",
        "        print(\"\\nOptimized Random Forest Parameters:\")\n",
        "        print(optimized_params)\n",
        "        print(f\"Best ROC-AUC: {-best_cost:.4f}\")\n",
        "\n",
        "        self.models['RandomForest']['params'] = optimized_params\n",
        "        return optimized_params\n",
        "\n",
        "    def train_random_forest(self) -> Dict[str, Union[float, str]]:\n",
        "        \"\"\"Train Random Forest with optimized parameters\"\"\"\n",
        "        if not self.models['RandomForest']['params']:\n",
        "            raise ValueError(\"Random Forest parameters not tuned. Call tune_random_forest() first.\")\n",
        "\n",
        "        params = self.models['RandomForest']['params']\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=params['n_estimators'],\n",
        "            max_depth=params['max_depth'],\n",
        "            min_samples_split=params['min_samples_split'],\n",
        "            max_features=params['max_features'],\n",
        "            class_weight='balanced_subsample',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(self.X_train, self.y_train)\n",
        "        return self._evaluate_model(model, \"Random Forest\")\n",
        "\n",
        "    # ==================== XGBoost ====================\n",
        "    def tune_xgboost(self, n_particles: int = 5, iters: int = 10) -> Dict[str, float]:\n",
        "        \"\"\"PSO optimization for XGBoost hyperparameters\"\"\"\n",
        "\n",
        "        bounds = (\n",
        "            np.array([0.01, 3, 0.1, 0.1, 0.1, 0]),  # min values\n",
        "            np.array([0.3, 10, 10, 1, 1, 5])        # max values\n",
        "        )\n",
        "\n",
        "        def objective_function(params):\n",
        "            scores = []\n",
        "            for param_set in params:\n",
        "                model = XGBClassifier(\n",
        "                    learning_rate=param_set[0],\n",
        "                    max_depth=int(param_set[1]),\n",
        "                    min_child_weight=param_set[2],\n",
        "                    subsample=param_set[3],\n",
        "                    colsample_bytree=param_set[4],\n",
        "                    gamma=param_set[5],\n",
        "                    scale_pos_weight=np.sqrt(len(self.y_train)/self.y_train.sum()),\n",
        "                    tree_method='hist',\n",
        "                    eval_metric='aucpr',\n",
        "                    random_state=42\n",
        "                )\n",
        "\n",
        "                cv_scores = []\n",
        "                cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "                for train_idx, val_idx in cv.split(self.X_train, self.y_train):\n",
        "                    X_train_cv, X_val_cv = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]\n",
        "                    y_train_cv, y_val_cv = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n",
        "\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    y_proba = model.predict_proba(X_val_cv)[:, 1]\n",
        "                    score = roc_auc_score(y_val_cv, y_proba)\n",
        "                    cv_scores.append(score)\n",
        "\n",
        "                scores.append(-np.mean(cv_scores))\n",
        "\n",
        "            return np.array(scores)\n",
        "\n",
        "        optimizer = GlobalBestPSO(\n",
        "            n_particles=n_particles,\n",
        "            dimensions=len(bounds[0]),\n",
        "            options={'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3},\n",
        "            bounds=bounds\n",
        "        )\n",
        "\n",
        "        best_cost, best_params = optimizer.optimize(objective_function, iters=iters)\n",
        "\n",
        "        optimized_params = {\n",
        "            'learning_rate': best_params[0],\n",
        "            'max_depth': int(best_params[1]),\n",
        "            'min_child_weight': best_params[2],\n",
        "            'subsample': best_params[3],\n",
        "            'colsample_bytree': best_params[4],\n",
        "            'gamma': best_params[5]\n",
        "        }\n",
        "\n",
        "        print(\"\\nOptimized XGBoost Parameters:\")\n",
        "        print(optimized_params)\n",
        "        print(f\"Best ROC-AUC: {-best_cost:.4f}\")\n",
        "\n",
        "        self.models['XGBoost']['params'] = optimized_params\n",
        "        return optimized_params\n",
        "\n",
        "    def train_xgboost(self) -> Dict[str, Union[float, str]]:\n",
        "        \"\"\"Train XGBoost with optimized parameters\"\"\"\n",
        "        if not self.models['XGBoost']['params']:\n",
        "            raise ValueError(\"XGBoost parameters not tuned. Call tune_xgboost() first.\")\n",
        "\n",
        "        params = self.models['XGBoost']['params']\n",
        "        model = XGBClassifier(\n",
        "            learning_rate=params['learning_rate'],\n",
        "            max_depth=params['max_depth'],\n",
        "            min_child_weight=params['min_child_weight'],\n",
        "            subsample=params['subsample'],\n",
        "            colsample_bytree=params['colsample_bytree'],\n",
        "            gamma=params['gamma'],\n",
        "            scale_pos_weight=np.sqrt(len(self.y_train)/self.y_train.sum()),\n",
        "            tree_method='hist',\n",
        "            eval_metric='aucpr',\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(self.X_train, self.y_train)\n",
        "        return self._evaluate_model(model, \"XGBoost\")\n",
        "\n",
        "    # ==================== LightGBM ====================\n",
        "    def tune_lightgbm(self, n_particles: int = 5, iters: int = 10) -> Dict[str, float]:\n",
        "        \"\"\"PSO optimization for LightGBM hyperparameters\"\"\"\n",
        "\n",
        "        bounds = (\n",
        "            np.array([0.01, 3, 0.1, 0.1, 0.1, 20]),  # min values\n",
        "            np.array([0.3, 50, 100, 1, 1, 50])       # max values\n",
        "        )\n",
        "\n",
        "        def objective_function(params):\n",
        "            scores = []\n",
        "            for param_set in params:\n",
        "                model = LGBMClassifier(\n",
        "                    learning_rate=param_set[0],\n",
        "                    num_leaves=int(param_set[1]),\n",
        "                    min_data_in_leaf=int(param_set[2]),\n",
        "                    feature_fraction=param_set[3],\n",
        "                    bagging_fraction=param_set[4],\n",
        "                    bagging_freq=int(param_set[5]),\n",
        "                    class_weight='balanced',\n",
        "                    boosting_type='gbdt',\n",
        "                    objective='binary',\n",
        "                    random_state=42\n",
        "                )\n",
        "\n",
        "                cv_scores = []\n",
        "                cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "                for train_idx, val_idx in cv.split(self.X_train, self.y_train):\n",
        "                    X_train_cv, X_val_cv = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]\n",
        "                    y_train_cv, y_val_cv = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n",
        "\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    y_proba = model.predict_proba(X_val_cv)[:, 1]\n",
        "                    score = roc_auc_score(y_val_cv, y_proba)\n",
        "                    cv_scores.append(score)\n",
        "\n",
        "                scores.append(-np.mean(cv_scores))\n",
        "\n",
        "            return np.array(scores)\n",
        "\n",
        "        optimizer = GlobalBestPSO(\n",
        "            n_particles=n_particles,\n",
        "            dimensions=len(bounds[0]),\n",
        "            options={'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3},\n",
        "            bounds=bounds\n",
        "        )\n",
        "\n",
        "        best_cost, best_params = optimizer.optimize(objective_function, iters=iters)\n",
        "\n",
        "        optimized_params = {\n",
        "            'learning_rate': best_params[0],\n",
        "            'num_leaves': int(best_params[1]),\n",
        "            'min_data_in_leaf': int(best_params[2]),\n",
        "            'feature_fraction': best_params[3],\n",
        "            'bagging_fraction': best_params[4],\n",
        "            'bagging_freq': int(best_params[5])\n",
        "        }\n",
        "\n",
        "        print(\"\\nOptimized LightGBM Parameters:\")\n",
        "        print(optimized_params)\n",
        "        print(f\"Best ROC-AUC: {-best_cost:.4f}\")\n",
        "\n",
        "        self.models['LightGBM']['params'] = optimized_params\n",
        "        return optimized_params\n",
        "\n",
        "    def train_lightgbm(self) -> Dict[str, Union[float, str]]:\n",
        "        \"\"\"Train LightGBM with optimized parameters\"\"\"\n",
        "        if not self.models['LightGBM']['params']:\n",
        "            raise ValueError(\"LightGBM parameters not tuned. Call tune_lightgbm() first.\")\n",
        "\n",
        "        params = self.models['LightGBM']['params']\n",
        "        model = LGBMClassifier(\n",
        "            learning_rate=params['learning_rate'],\n",
        "            num_leaves=params['num_leaves'],\n",
        "            min_data_in_leaf=params['min_data_in_leaf'],\n",
        "            feature_fraction=params['feature_fraction'],\n",
        "            bagging_fraction=params['bagging_fraction'],\n",
        "            bagging_freq=params['bagging_freq'],\n",
        "            class_weight='balanced',\n",
        "            boosting_type='gbdt',\n",
        "            objective='binary',\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(self.X_train, self.y_train)\n",
        "        return self._evaluate_model(model, \"LightGBM\")\n",
        "\n",
        "    # ==================== Dense Neural Network ====================\n",
        "    def _create_dense_nn(self, input_dim: int, layers: Tuple[int, ...] = (64, 32),\n",
        "                         learning_rate: float = 0.001, dropout_rate: float = 0.2) -> Sequential:\n",
        "        \"\"\"Create a dense neural network architecture\"\"\"\n",
        "        model = Sequential()\n",
        "        model.add(Input((input_dim,)))\n",
        "        model.add(Dense(layers[0], activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "        for units in layers[1:]:\n",
        "            model.add(Dense(units, activation='relu'))\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=learning_rate),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def tune_dense_nn(self, n_particles: int = 5, iters: int = 10) -> Dict[str, float]:\n",
        "        \"\"\"PSO optimization for Dense NN hyperparameters\"\"\"\n",
        "\n",
        "        # Scale data for NN\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
        "\n",
        "        bounds = (\n",
        "            np.array([0.0001, 16, 16, 0.1, 0.1]),  # min values\n",
        "            np.array([0.01, 256, 256, 0.5, 0.5])   # max values\n",
        "        )\n",
        "\n",
        "        def objective_function(params):\n",
        "            scores = []\n",
        "            for param_set in params:\n",
        "                model = KerasClassifier(\n",
        "                    model=lambda: self._create_dense_nn(\n",
        "                        input_dim=X_train_scaled.shape[1],\n",
        "                        layers=(int(param_set[1]), int(param_set[2])),\n",
        "                        learning_rate=param_set[0],\n",
        "                        dropout_rate=param_set[4]\n",
        "                    ),\n",
        "                    epochs=10,\n",
        "                    batch_size=256,\n",
        "                    verbose=0\n",
        "                )\n",
        "\n",
        "                cv_scores = []\n",
        "                cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "                for train_idx, val_idx in cv.split(X_train_scaled, self.y_train):\n",
        "                    X_train_cv, X_val_cv = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "                    y_train_cv, y_val_cv = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n",
        "\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    y_proba = model.predict_proba(X_val_cv)[:, 1]\n",
        "                    score = roc_auc_score(y_val_cv, y_proba)\n",
        "                    cv_scores.append(score)\n",
        "\n",
        "                scores.append(-np.mean(cv_scores))\n",
        "\n",
        "            return np.array(scores)\n",
        "\n",
        "        optimizer = GlobalBestPSO(\n",
        "            n_particles=n_particles,\n",
        "            dimensions=len(bounds[0]),\n",
        "            options={'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3},\n",
        "            bounds=bounds\n",
        "        )\n",
        "\n",
        "        best_cost, best_params = optimizer.optimize(objective_function, iters=iters)\n",
        "\n",
        "        optimized_params = {\n",
        "            'learning_rate': best_params[0],\n",
        "            'layer1': int(best_params[1]),\n",
        "            'layer2': int(best_params[2]),\n",
        "            'dropout_rate': best_params[4]\n",
        "        }\n",
        "\n",
        "        print(\"\\nOptimized Dense NN Parameters:\")\n",
        "        print(optimized_params)\n",
        "        print(f\"Best ROC-AUC: {-best_cost:.4f}\")\n",
        "\n",
        "        self.models['DenseNN']['params'] = optimized_params\n",
        "        return optimized_params\n",
        "\n",
        "    def train_dense_nn(self) -> Dict[str, Union[float, str]]:\n",
        "        \"\"\"Train Dense NN with optimized parameters\"\"\"\n",
        "        if not self.models['DenseNN']['params']:\n",
        "            raise ValueError(\"Dense NN parameters not tuned. Call tune_dense_nn() first.\")\n",
        "\n",
        "        params = self.models['DenseNN']['params']\n",
        "\n",
        "        # Scale data\n",
        "        X_train_scaled = self.scaler.transform(self.X_train)\n",
        "\n",
        "        model = KerasClassifier(\n",
        "            model=lambda: self._create_dense_nn(\n",
        "                input_dim=X_train_scaled.shape[1],\n",
        "                layers=(params['layer1'], params['layer2']),\n",
        "                learning_rate=params['learning_rate'],\n",
        "                dropout_rate=params['dropout_rate']\n",
        "            ),\n",
        "            epochs=50,\n",
        "            batch_size=256,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        model.fit(X_train_scaled, self.y_train)\n",
        "        return self._evaluate_model(model, \"Dense Neural Network\", is_nn=True)\n",
        "\n",
        "    # ==================== Evaluation ====================\n",
        "    def _evaluate_model(self, model, model_name: str, is_nn: bool = False,\n",
        "                        X_test: Optional[np.ndarray] = None) -> Dict[str, Union[float, str]]:\n",
        "        \"\"\"Evaluate model performance and create visualizations\"\"\"\n",
        "        if X_test is None:\n",
        "            X_test = self.X_test\n",
        "\n",
        "        if is_nn:\n",
        "            y_proba = model.predict_proba(X_test)[:, 1]\n",
        "            y_pred = (y_proba > 0.5).astype(int)\n",
        "        else:\n",
        "            y_proba = model.predict_proba(X_test)[:, 1]\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "        # Metrics calculation\n",
        "        metrics = {\n",
        "            \"roc_auc\": roc_auc_score(self.y_test, y_proba),\n",
        "            \"pr_auc\": average_precision_score(self.y_test, y_proba),\n",
        "            \"classification_report\": classification_report(self.y_test, y_pred)\n",
        "        }\n",
        "\n",
        "        if not is_nn and hasattr(model, 'feature_importances_'):\n",
        "            metrics[\"feature_importance\"] = model.feature_importances_\n",
        "\n",
        "        # Visualization\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        ConfusionMatrixDisplay.from_predictions(self.y_test, y_pred, ax=ax[0])\n",
        "        ax[0].set_title(f\"Confusion Matrix - {model_name}\")\n",
        "\n",
        "        if not is_nn and hasattr(model, 'feature_importances_'):\n",
        "            # Top 10 most valuable features\n",
        "            top_features = self.X.columns[\n",
        "                np.argsort(metrics.get('feature_importance', np.zeros(self.X.shape[1])))[-10:]\n",
        "            ]\n",
        "            ax[1].barh(top_features, metrics.get('feature_importance', np.zeros(self.X.shape[1]))[-10:])\n",
        "            ax[1].set_title(f\"Top 10 Features - {model_name}\")\n",
        "        else:\n",
        "            ax[1].axis('off')\n",
        "\n",
        "        fig.tight_layout()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def run_pipeline(self, models_to_run: List[str] = None,\n",
        "                     selected_features: List[int] = None) -> Dict[str, Dict[str, Union[float, str]]]:\n",
        "        \"\"\"\n",
        "        Run the complete pipeline with optional model selection\n",
        "\n",
        "        Args:\n",
        "            models_to_run: List of model names to run (None for all)\n",
        "            feature_selection: Whether to perform feature selection\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of results for each model\n",
        "        \"\"\"\n",
        "        if models_to_run is None:\n",
        "            models_to_run = list(self.models.keys())\n",
        "\n",
        "        # Perform feature selection if requested\n",
        "        if selected_features is None:\n",
        "            self.selected_features = list(range(self.X.shape[1]))\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for model_name in models_to_run:\n",
        "            if model_name not in self.models:\n",
        "                print(f\"Warning: Model {model_name} not found in available models. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n=== Processing {model_name} ===\")\n",
        "\n",
        "            # Tune hyperparameters\n",
        "            print(f\"Tuning {model_name} hyperparameters...\")\n",
        "            self.models[model_name]['tune_func']()\n",
        "\n",
        "            # Train model with optimized parameters\n",
        "            print(f\"Training {model_name} with optimized parameters...\")\n",
        "            results[model_name] = self.models[model_name]['train_func']()\n",
        "\n",
        "            # Print results\n",
        "            print(f\"\\n{model_name} Results:\")\n",
        "            print(f\"ROC-AUC: {results[model_name]['roc_auc']:.4f}\")\n",
        "            print(f\"PR-AUC: {results[model_name]['pr_auc']:.4f}\")\n",
        "            print(\"Classification Report:\")\n",
        "            print(results[model_name]['classification_report'])\n",
        "\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f2963a",
      "metadata": {
        "id": "e0f2963a"
      },
      "source": [
        "Features obtained from GA feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03240d69",
      "metadata": {
        "id": "03240d69"
      },
      "outputs": [],
      "source": [
        "features = [2, 4, 8, 9, 12, 13, 14, 15, 16, 23, 24, 27, 28, 34, 37, 39, 45, 47, 49, 51, 52, 53, 56, 58, 59, 60, 61, 62, 65, 67, 68, 70, 72, 73, 74, 75, 76, 78, 80, 81, 82, 86, 88, 90, 93, 94, 98, 100, 101, 105, 109, 110, 114, 117, 119, 120, 122, 124, 125, 126, 127, 128, 133, 135, 136, 144, 153, 156, 158, 159, 160, 167, 169, 173, 177, 179, 180, 182, 184, 185, 187, 188, 189, 190, 195, 198, 202, 206, 208, 209, 210, 212, 216, 223, 227, 230, 234, 236, 239, 246, 247, 251, 255, 261, 264, 266, 269, 272, 277, 280, 282, 283, 284, 286, 288, 290, 293, 296, 300, 303, 307, 311, 313, 314, 315, 319, 320, 321, 323, 324, 325, 329, 334, 339, 342, 347, 348, 352, 353, 355, 358, 361, 366, 368, 369, 370, 371, 373, 378, 382, 384, 386, 387, 389, 391]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31068be",
      "metadata": {
        "id": "a31068be"
      },
      "source": [
        "### Hyperparameter Tuning and Evaluation using Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "42f0d78c",
      "metadata": {
        "id": "42f0d78c"
      },
      "outputs": [],
      "source": [
        "pipeline_balanced = ModelPipeline(\n",
        "    data_path='fraud_data.parquet',\n",
        "    sample_frac=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b9f2578",
      "metadata": {
        "id": "7b9f2578"
      },
      "source": [
        "Random Forest Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "36e243bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "36e243bf",
        "outputId": "43ec2ee8-71d9-4038-b0ec-408503ea010a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-15 08:50:04,315 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing RandomForest ===\n",
            "Tuning RandomForest hyperparameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best: 100%|██████████|10/10, best_cost=-0.894\n",
            "2025-04-15 09:04:19,979 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.894091809110226, best pos: [478.44753951  26.94722093   5.43889144  28.15059517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized Random Forest Parameters:\n",
            "{'n_estimators': 478, 'max_depth': 26, 'min_samples_split': 5, 'max_features': 28}\n",
            "Best ROC-AUC: 0.8941\n",
            "Training RandomForest with optimized parameters...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RandomForest Results:\n",
            "ROC-AUC: 0.9045\n",
            "PR-AUC: 0.5389\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.84      0.91    113866\n",
            "         1.0       0.16      0.81      0.27      4242\n",
            "\n",
            "    accuracy                           0.84    118108\n",
            "   macro avg       0.58      0.83      0.59    118108\n",
            "weighted avg       0.96      0.84      0.89    118108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results_rf_balanced = pipeline_balanced.run_pipeline(\n",
        "    models_to_run=[\n",
        "        'RandomForest'\n",
        "    ],\n",
        "    selected_features=features\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ece46e6",
      "metadata": {
        "id": "5ece46e6"
      },
      "source": [
        "XGBoost Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3fb0884f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "3fb0884f",
        "outputId": "058d3f9d-a69f-4d63-e07d-994d81184800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-15 09:07:20,611 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing XGBoost ===\n",
            "Tuning XGBoost hyperparameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best: 100%|██████████|10/10, best_cost=-0.907\n",
            "2025-04-15 09:12:30,129 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.9068439254841705, best pos: [0.28401961 7.8029476  6.17243871 0.98841606 0.88788678 0.32766076]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized XGBoost Parameters:\n",
            "{'learning_rate': np.float64(0.28401960527716236), 'max_depth': 7, 'min_child_weight': np.float64(6.172438714409442), 'subsample': np.float64(0.9884160626446158), 'colsample_bytree': np.float64(0.8878867794274299), 'gamma': np.float64(0.3276607618022003)}\n",
            "Best ROC-AUC: 0.9068\n",
            "Training XGBoost with optimized parameters...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost Results:\n",
            "ROC-AUC: 0.9175\n",
            "PR-AUC: 0.5607\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.83      0.91    113866\n",
            "         1.0       0.16      0.85      0.27      4242\n",
            "\n",
            "    accuracy                           0.83    118108\n",
            "   macro avg       0.58      0.84      0.59    118108\n",
            "weighted avg       0.96      0.83      0.88    118108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results_xg_balanced = pipeline_balanced.run_pipeline(\n",
        "    models_to_run=[\n",
        "        'XGBoost'\n",
        "    ],\n",
        "    selected_features=features\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca442d41",
      "metadata": {
        "id": "ca442d41"
      },
      "source": [
        "LightGBM Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85552b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "85552b54",
        "outputId": "6bd89bd5-27f6-4ea7-cfa3-98289de14522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-15 09:12:36,455 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing LightGBM ===\n",
            "Tuning LightGBM hyperparameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rpyswarms.single.global_best:   0%|          |0/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019542 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18732\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 370\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18426\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018557 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18469\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 371\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5096981341736211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5096981341736211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.11045848591729057, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11045848591729057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021255 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017754 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3624963208383729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3624963208383729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7254836975138883, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254836975138883\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017681 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020397 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1944371605763574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1944371605763574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.31784051427627474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31784051427627474\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030058 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322184734896936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322184734896936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6036838151382227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6036838151382227\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018946 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18751\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 377\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018197 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18455\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 377\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018344 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18492\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 377\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  10%|█         |1/10, best_cost=-0.898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4155642380882627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4155642380882627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.12988279791222992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12988279791222992\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017725 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020309 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018175 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.19818883357264397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19818883357264397\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9207806157186312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207806157186312\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019417 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] bagging_freq is set=46, subsample_freq=0 will be ignored. Current value: bagging_freq=46\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9983244746765839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9983244746765839\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7539112278569662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7539112278569662\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031550 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028669 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030872 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9849427183518658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9849427183518658\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1480591033686475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1480591033686475\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018946 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031006 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018898 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6174801073833599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6174801073833599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2277361548393663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2277361548393663\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18751\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 377\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017636 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18451\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 375\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18485\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 374\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  20%|██        |2/10, best_cost=-0.905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16579872224691697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16579872224691697\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2675376971341912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2675376971341912\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019421 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019063 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7278304630317646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7278304630317646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7500705325398379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7500705325398379\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018452 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021589 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4464018073727808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4464018073727808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7953230378775958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7953230378775958\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027648 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018175 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
            "[LightGBM] [Warning] feature_fraction is set=0.24098600150265162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.24098600150265162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8429793482682655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429793482682655\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018298 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018692 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3689762807117104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3689762807117104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8079142535481875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079142535481875\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019348 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18738\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 372\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019373 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18444\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 373\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019074 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18481\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 373\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  30%|███       |3/10, best_cost=-0.905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7578571644959474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578571644959474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43098490789129806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43098490789129806\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018774 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017068 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017226 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.12277877338549961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12277877338549961\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5972801333706336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5972801333706336\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028665 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029792 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018916 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] bagging_freq is set=42, subsample_freq=0 will be ignored. Current value: bagging_freq=42\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272361778271264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272361778271264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8633747168472146, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8633747168472146\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018169 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018311 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.376719901584025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.376719901584025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5776543899388485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5776543899388485\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019246 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019397 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018949 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9361988205174885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9361988205174885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4377698712044339, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4377698712044339\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018149 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18721\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017769 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017895 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  40%|████      |4/10, best_cost=-0.905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3128888811540472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3128888811540472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6338926310803867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6338926310803867\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027251 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018069 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4072665900050043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4072665900050043\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4714005072956694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4714005072956694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019493 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019456 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019428 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8966362232074105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966362232074105\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368322593185496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368322593185496\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023125 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017786 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018149 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.47246876617660694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47246876617660694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.417724682701876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.417724682701876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019017 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017413 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1484838586777494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1484838586777494\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1984186145550794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1984186145550794\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029874 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018837 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  50%|█████     |5/10, best_cost=-0.905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7766410747238162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7766410747238162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8073233386215419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073233386215419\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020541 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018876 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] bagging_freq is set=35, subsample_freq=0 will be ignored. Current value: bagging_freq=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6280476067044604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6280476067044604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5505931365030626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5505931365030626\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019008 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18721\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020860 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019992 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8617326793763518, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617326793763518\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10202011176829454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.10202011176829454\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019629 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018743 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5048543040039335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5048543040039335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19901802606886024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19901802606886024\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018424 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18721\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017499 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025838 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3023418509208302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3023418509208302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18966438642962516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.18966438642962516\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025383 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026760 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017483 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  60%|██████    |6/10, best_cost=-0.905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] bagging_freq is set=33, subsample_freq=0 will be ignored. Current value: bagging_freq=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1791653401415935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1791653401415935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9823963517319954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823963517319954\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019995 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018409 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018919 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.574486368492484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.574486368492484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5740472542037539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5740472542037539\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019078 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18738\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 372\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020312 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18433\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 371\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018924 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18473\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 372\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.74915771271143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74915771271143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238392209355769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238392209355769\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018274 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025744 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027858 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018486 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18732\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 370\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018240 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18426\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019237 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18466\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 370\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4414351457688843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414351457688843\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4432217814522502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4432217814522502\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018983 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018915 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018055 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  70%|███████   |7/10, best_cost=-0.906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4537370062526679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4537370062526679\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.23675451131922678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23675451131922678\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18721\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018444 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35087281900458234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35087281900458234\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.535317843176426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.535317843176426\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019385 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18738\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 372\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027860 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18430\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 370\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029438 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18473\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 372\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6809565456677976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6809565456677976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2362890403782231, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2362890403782231\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019665 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017939 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017836 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35258619417963566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35258619417963566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7940986487129417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7940986487129417\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019122 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018740 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] bagging_freq is set=27, subsample_freq=0 will be ignored. Current value: bagging_freq=27\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5478201315249662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5478201315249662\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.724086517448791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.724086517448791\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019254 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019356 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  80%|████████  |8/10, best_cost=-0.906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6694979176969308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694979176969308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6893240669443793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6893240669443793\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026652 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18721\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025752 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018810 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] bagging_freq is set=49, subsample_freq=0 will be ignored. Current value: bagging_freq=49\n",
            "[LightGBM] [Warning] feature_fraction is set=0.16994115708287333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16994115708287333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5970373030780004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5970373030780004\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027354 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019213 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5697210582293823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5697210582293823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8936392924433473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8936392924433473\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018151 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017695 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3359467751398292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3359467751398292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6601351249198998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6601351249198998\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019932 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019320 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6163316547418926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6163316547418926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9270971553713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270971553713879\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028529 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020132 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  90%|█████████ |9/10, best_cost=-0.906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7416855965381483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7416855965381483\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2580578502574865, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2580578502574865\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019018 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18718\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018957 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18463\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 369\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9684673201467143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684673201467143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138925792189118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138925792189118\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019055 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018576 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018328 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4598378104620236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4598378104620236\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5955557234911685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5955557234911685\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018408 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017900 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18423\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018060 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.37033766141298663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37033766141298663\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5095654554967725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5095654554967725\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031174 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036377 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019423 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18456\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6269286923812503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6269286923812503\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9725756064787702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9725756064787702\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Info] Number of positive: 3338, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018566 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18715\n",
            "[LightGBM] [Info] Number of data points in the train set: 6568, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18419\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 367\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "[LightGBM] [Info] Number of positive: 3339, number of negative: 3230\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018212 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 18460\n",
            "[LightGBM] [Info] Number of data points in the train set: 6569, number of used features: 368\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best: 100%|██████████|10/10, best_cost=-0.906\n",
            "2025-04-15 09:15:04,925 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.9062353678506493, best pos: [ 0.21926592 24.22562921 37.99504906  0.42471319  0.98590256 29.87415142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] bagging_freq is set=30, subsample_freq=0 will be ignored. Current value: bagging_freq=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4904637364166493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4904637364166493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2530412343704288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2530412343704288\n",
            "\n",
            "Optimized LightGBM Parameters:\n",
            "{'learning_rate': np.float64(0.21926592164943762), 'num_leaves': 24, 'min_data_in_leaf': 37, 'feature_fraction': np.float64(0.4247131935700925), 'bagging_fraction': np.float64(0.9859025643025873), 'bagging_freq': 29}\n",
            "Best ROC-AUC: 0.9062\n",
            "Training LightGBM with optimized parameters...\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Info] Number of positive: 5008, number of negative: 4845\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21035\n",
            "[LightGBM] [Info] Number of data points in the train set: 9853, number of used features: 373\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4247131935700925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4247131935700925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9859025643025873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859025643025873\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAyc5JREFUeJzs3XlcTfn/B/DXLXXbS0rLSEVRKJJBDEJKtmhmbI1JY5usMZaxlexLlhhj32ksg+wlS6Opxl62SEYY+572uvf+/ujX+boKLbcir+fjcR6Pez/ncz7nfU7J7d378zkimUwmAxERERERERERUTlSqugAiIiIiIiIiIjoy8OkFBERERERERERlTsmpYiIiIiIiIiIqNwxKUVEREREREREROWOSSkiIiIiIiIiIip3TEoREREREREREVG5Y1KKiIiIiIiIiIjKHZNSRERERERERERU7piUIiIiIiIiIiKicsekFBEREREREdEnpH///rCwsCjxsVpaWooNiKiMMClFRERERET0HiKRqEhbZGRkmceyYsUKfP/996hZsyZEIhH69+//3r6vXr3C4MGDYWhoCE1NTbRt2xYXLlwo0nmcnZ3fe53Xr19X0NXI+/3337Fx48YyGftTY2FhgS5dulR0GEhPT8e0adM++L176dIl+Pj4wNLSEmpqatDS0kKjRo0wfvx4/Pvvv3J9+/fvL/e9UqVKFZiZmaF37964du2aXN/IyEih39atWws9d8uWLSESidCgQYNSXyt9uqpUdABERERERESfqi1btsi937x5MyIiIgq029ralnks8+bNw5s3b9C0aVM8fPjwvf2kUik6d+6M+Ph4jBs3DgYGBvj999/h7OyM8+fPw9ra+qPnqlGjBubMmVOg3dTUtFTX8D6///47DAwMPpho+5KsWbMGUqm0TM+Rnp6OwMBAAHmJyMJi8PX1hYGBAby8vGBjY4Pc3FxcuXIFmzdvxpIlS5CRkQFlZWXhGLFYjLVr1wIAcnNzcevWLaxcuRJhYWG4du1age8fNTU1hISE4IcffpBrT05ORkxMDNTU1BR81fSpYVKKiIiIiIjoPd79Zfmff/5BREREgfby8NdffwlVUh+anvXnn38iJiYGu3btwnfffQcA6NmzJ+rUqYOAgACEhIR89Fy6uroVco2KJJPJkJmZCXV19YoOpdhUVFQq9PwxMTHw9fVFy5YtcfDgQWhra8vtX7hwIWbNmlXguCpVqhT4vmnevDm6dOmCQ4cOYdCgQXL7OnXqhP379+PZs2cwMDAQ2kNCQmBkZARra2u8fPlSgVdGnxpO3yMiIiIiIiqFtLQ0/PLLLzAzM4NYLEbdunURFBQEmUwm108kEmH48OHYtm0b6tatCzU1NTg6OuLUqVNFOo+5uTlEItFH+/35558wMjKCp6en0GZoaIiePXti3759yMrKKt4FFiIrKwsBAQGwsrKCWCyGmZkZxo8fX2DsDRs2oF27dqhevTrEYjHq1auHFStWyPWxsLDA1atX8ddffwlTuvIrd6ZNm1boNW/cuBEikQjJycly43Tp0gXh4eFo0qQJ1NXVsWrVKgB50xn9/PyEr5GVlRXmzZtXoBpp+/btcHR0hLa2NnR0dGBnZ4fg4OBS36/iKmxNqefPn6Nfv37Q0dGBnp4evL29ER8fD5FIVOjUx/v376N79+7Q0tKCoaEhxo4dC4lEAiCvEsnQ0BAAEBgYKNz3adOmybVt27atQEIKyKtwmjFjhlyV1PsYGxsDyEtYvcvDwwNisRi7du2Saw8JCUHPnj2LND593lgpRUREREREVEIymQzdunXDyZMnMWDAADRq1Ajh4eEYN24c7t+/j8WLF8v1/+uvv7Bjxw6MHDkSYrEYv//+Ozp27IgzZ84obO2cixcvonHjxlBSkq9BaNq0KVavXo3ExETY2dl9cAyJRIJnz57JteWvKSSVStGtWzf8/fffGDx4MGxtbXH58mUsXrwYiYmJCA0NFY5ZsWIF6tevj27duqFKlSo4cOAAhg4dCqlUimHDhgEAlixZghEjRkBLSwuTJ08GABgZGZXo2m/cuIE+ffpgyJAhGDRoEOrWrYv09HS0adMG9+/fx5AhQ1CzZk3ExMRg4sSJePjwIZYsWQIAiIiIQJ8+fdC+fXvMmzcPAJCQkIDo6GiMGjWqRPEoilQqRdeuXXHmzBn4+vrCxsYG+/btg7e3d6H9JRIJ3Nzc0KxZMwQFBeHYsWNYuHAhateuDV9fXxgaGmLFihXw9fVFjx49hASmvb090tPTceLECTg7O6NGjRrFjjX/+0YikeDff//FhAkTUK1atULX0dLQ0ICHhwf++OMP+Pr6AgDi4+Nx9epVrF27FpcuXSr2+ekzIyMiIiIiIqIiGTZsmOztX6NCQ0NlAGQzZ86U6/fdd9/JRCKRLCkpSWgDIAMgO3funNB2584dmZqamqxHjx7FikNTU1Pm7e393n0//fRTgfZDhw7JAMjCwsI+OHabNm2EWN/e8s+3ZcsWmZKSkiwqKkruuJUrV8oAyKKjo4W29PT0AuO7ubnJatWqJddWv359WZs2bQr0DQgIkBX2a+uGDRtkAGS3b98W2szNzQu9vhkzZsg0NTVliYmJcu2//vqrTFlZWXb37l2ZTCaTjRo1SqajoyPLzc0teFMUyNzcXNa5c+cP9vH29paZm5sL73fv3i0DIFuyZInQJpFIZO3atZMBkG3YsEHuWACy6dOny43p4OAgc3R0FN4/ffpUBkAWEBAg1y8+Pl4GQObn51cgrufPn8uePn0qbFlZWQXO++721Vdfyc6fPy83zsmTJ2UAZLt27ZIdPHhQJhKJhK/DuHHjhO+PNm3ayOrXr//Be0WfN07fIyIiIiIiKqHDhw9DWVkZI0eOlGv/5ZdfIJPJcOTIEbl2JycnODo6Cu9r1qwJDw8PhIeHC1OrSisjIwNisbhAe/6i0RkZGR8dw8LCAhEREXLb+PHjAQC7du2Cra0tbGxs8OzZM2Fr164dAODkyZPCOG+v5/T69Ws8e/YMbdq0wb///ovXr1+X6joLY2lpCTc3N7m2Xbt2oVWrVqhatapcvC4uLpBIJML0ST09PaSlpSEiIkLhcZVWWFgYVFRU5NZkUlJSEqrNCvPzzz/LvW/VqlWBJ+YVJiUlBQAKXbesVq1aMDQ0FLb9+/fL7VdTUxO+X8LDw7Fq1SpoaWmhU6dOSExMLPR8rq6u0NfXx/bt2yGTybB9+3b06dPno3FS5cDpe0RERERERCV0584dmJqaFlh3J/9pfHfu3JFrL+zJd3Xq1EF6ejqePn0qrL9TGurq6oWuG5WZmSns/xhNTU24uLgUuu/mzZtISEgQ1iR615MnT4TX0dHRCAgIQGxsLNLT0+X6vX79Grq6uh+NpTgsLS0LjffSpUsfjXfo0KHYuXMn3N3d8dVXX8HV1RU9e/ZEx44dP3jOp0+fyiUUtbS0PrgQfUncuXMHJiYm0NDQkGu3srIqtL+amlqB661atWqRFg3P/15OTU0tsG/fvn3IyclBfHw8xo4dW2C/srJyge+bTp06wdraGhMnTsTu3bsLHKOiooLvv/8eISEhaNq0Ke7du4e+fft+NE6qHJiUIiIiIiIiqkRMTEzw8OHDAu35baampqUaXyqVws7ODosWLSp0v5mZGQDg1q1baN++PWxsbLBo0SKYmZlBVVUVhw8fxuLFiwssMl6Y9y3s/r6qssISblKpFB06dBAqvd5Vp04dAED16tURFxeH8PBwHDlyBEeOHMGGDRvw448/YtOmTe+N8euvv5ZLPgYEBAgLhleU0iwQbmVlhSpVquDKlSsF9rVp0wZA4YuWv0+NGjVQt27dDy7o37dvX6xcuRLTpk1Dw4YNUa9eveIHTp8lJqWIiIiIiIhKyNzcHMeOHcObN2/kqqWuX78u7H/bzZs3C4yRmJgIDQ2N91byFFejRo0QFRUFqVQqt9j56dOnoaGhISRhSqp27dqIj49H+/btP/g0wAMHDiArKwv79+9HzZo1hfa3p/fle984VatWBZD39Dw9PT2h/d0KtI/Fm5qa+t7Kr7epqqqia9eu6Nq1K6RSKYYOHYpVq1Zh6tSp761K2rZtm9yUyFq1ahU5tqIyNzfHyZMnkZ6eLlctlZSUVOIx33fPNTU14ezsjL/++gv379/HV199VeJz5MvNzS208irfN998g5o1ayIyMlJYZJ6+DFxTioiIiIiIqIQ6deoEiUSC3377Ta598eLFEIlEcHd3l2uPjY3FhQsXhPf37t3Dvn374OrqWqrqlrd99913ePz4Mfbs2SO0PXv2DLt27ULXrl0LXW+qOHr27In79+9jzZo1BfZlZGQgLS0NwP+qdWQymbD/9evX2LBhQ4HjNDU18erVqwLttWvXBgC5Kpu0tLQPVi4VFm9sbCzCw8ML7Hv16hVyc3MBAM+fP5fbp6SkBHt7ewAodDpkvpYtW8LFxUXYyiIp5ebmhpycHLl7LpVKsXz58hKPmZ/cKuy++/v7QyKR4Icffig0mfT21/RjEhMTcePGDTRs2PC9fUQiEZYuXYqAgAD069evyGPT54+VUkRERERERCXUtWtXtG3bFpMnT0ZycjIaNmyIo0ePYt++ffDz8xOSKvkaNGgANzc3jBw5EmKxGL///jsAIDAw8KPnOnDgAOLj4wEAOTk5uHTpEmbOnAkA6Natm5BA+e6779C8eXP4+Pjg2rVrMDAwwO+//w6JRFKk83xMv379sHPnTvz88884efIkWrZsCYlEguvXr2Pnzp0IDw9HkyZN4OrqKlQeDRkyBKmpqVizZg2qV69eYHqho6MjVqxYgZkzZ8LKygrVq1dHu3bt4Orqipo1a2LAgAEYN24clJWVsX79ehgaGuLu3btFinfcuHHYv38/unTpgv79+8PR0RFpaWm4fPky/vzzTyQnJ8PAwAADBw7Eixcv0K5dO9SoUQN37tzBsmXL0KhRI2GNMEVJSkoSvnZvc3BwQOfOnQu0d+/eHU2bNsUvv/yCpKQk2NjYYP/+/Xjx4gWA91c9fYi6ujrq1auHHTt2oE6dOtDX10eDBg3QoEEDtGrVCr/99htGjBgBa2treHl5wcbGBtnZ2UhMTMS2bdugqqpaYA203NxcbN26FUBe0iw5ORkrV66EVCpFQEDAB+Px8PCAh4dHsa+DPnMV+/A/IiIiIiKiz8ewYcNk7/4a9ebNG9no0aNlpqamMhUVFZm1tbVswYIFMqlUKtcPgGzYsGGyrVu3yqytrWVisVjm4OAgO3nyZJHO7e3tLQNQ6LZhwwa5vi9evJANGDBAVq1aNZmGhoasTZs2srNnzxbpPG3atJHVr1//g32ys7Nl8+bNk9WvX18mFotlVatWlTk6OsoCAwNlr1+/Fvrt379fZm9vL1NTU5NZWFjI5s2bJ1u/fr0MgOz27dtCv0ePHsk6d+4s09bWlgGQtWnTRth3/vx5WbNmzWSqqqqymjVryhYtWiTbsGFDgTHMzc1lnTt3LjTeN2/eyCZOnCizsrKSqaqqygwMDGQtWrSQBQUFybKzs2UymUz2559/ylxdXWXVq1cXzjVkyBDZw4cPi3Tfisrc3Py9X8cBAwbIZLK8r7W5ubnccU+fPpX17dtXpq2tLdPV1ZX1799fFh0dLQMg2759u9DP29tbpqmpWeC8AQEBBb53Y2JiZI6OjjJVVVUZAFlAQIDc/osXL8p+/PFHWc2aNWWqqqoyTU1Nmb29veyXX36RJSUlyfUt7PtTR0dH1r59e9mxY8fk+p48eVIGQLZr164P3quifC/S500kkxWj7o6IiIiIiIhKRCQSYdiwYQWm+hGVVGhoKHr06IG///4bLVu2rOhwiIqNa0oRERERERERfeLeXkwdyHsC4bJly6Cjo4PGjRtXUFREpcM1pYiIiIiIiIg+cSNGjEBGRgacnJyQlZWFPXv2ICYmBrNnz4a6unpFh0dUIkxKEREREREREX3i2rVrh4ULF+LgwYPIzMyElZUVli1bhuHDh1d0aEQlxjWliIiIiIiIiIio3HFNKSIiIiIiIiIiKndMShERERERERERUbnjmlJERFQpZWZmIjs7W6FjqqqqQk1NTaFjEtGXQyqV4sGDB9DW1oZIJKrocIiIiMqMTCbDmzdvYGpqCiWl99dDMSlFRESVTmZmJizNtfDoiUSh4xobG+P27dtMTBFRiTx48ABmZmYVHQYREVG5uXfvHmrUqPHe/UxKERFRpZOdnY1HTyS4c94COtqKmame8kYKc8dkZGdnMylFRCWira0NIO8Duo6OTgVHQ0REVHZSUlJgZmYm/N/3PkxKERFRpaWlLYKWtmKmyEjBqTZEVDr5U/Z0dHSYlCIioi/Cx6arc6FzIiIiIiIiIiIqd6yUIiKiSksik0IiU9xYRERERESkOExKERFRpSWFDFIoJiulqHGIiIiIiCgPp+8REREREREREVG5Y6UUERFVWlJIoahJd4obiYiIiIiIAFZKERERERERERFRBWClFBERVVoSmQwSmWLWglLUOERERERElIdJKSIiqrS40DkRERER0aeL0/eIiIiIiIiIiKjcMSlF5ebmzZtwdXWFrq4uRCIRQkNDFTp+cnIyRCIRNm7cqNBxP2fOzs5wdnau6DDeq3///rCwsCjxsVpaWooNiCodKWSQKGhjpRQRERERkWIxKfWFuXXrFoYMGYJatWpBTU0NOjo6aNmyJYKDg5GRkVGm5/b29sbly5cxa9YsbNmyBU2aNCnT85Wn/v37QyQSQUdHp9D7ePPmTYhEIohEIgQFBRV7/AcPHmDatGmIi4tTQLTlw8LCAl26dKnoMJCeno5p06YhMjLyvX0uXboEHx8fWFpaQk1NDVpaWmjUqBHGjx+Pf//9V65v/tc6f6tSpQrMzMzQu3dvXLt2Ta5vZGSk0G/r1q2Fnrtly5YQiURo0KBBqa+ViIiIiIjoc8I1pb4ghw4dwvfffw+xWIwff/wRDRo0QHZ2Nv7++2+MGzcOV69exerVq8vk3BkZGYiNjcXkyZMxfPjwMjmHubk5MjIyoKKiUibjf0yVKlWQnp6OAwcOoGfPnnL7tm3bBjU1NWRmZpZo7AcPHiAwMBAWFhZo1KhRkY87evRoic5XXtasWQOpVFqm50hPT0dgYCAAFFo1tmbNGvj6+sLAwABeXl6wsbFBbm4urly5gs2bN2PJkiXIyMiAsrKycIxYLMbatWsBALm5ubh16xZWrlyJsLAwXLt2DaampnLnUFNTQ0hICH744Qe59uTkZMTExEBNTU3BV035uKYUEREREdGni0mpL8Tt27fRu3dvmJub48SJEzAxMRH2DRs2DElJSTh06FCZnf/p06cAAD09vTI7h0gkqtBf7sViMVq2bIk//vijQFIqJCQEnTt3xu7du8sllvT0dGhoaEBVVbVczldSFZVAzBcTEwNfX1+0bNkSBw8ehLa2ttz+hQsXYtasWQWOq1KlSoEEU/PmzdGlSxccOnQIgwYNktvXqVMn7N+/H8+ePYOBgYHQHhISAiMjI1hbW+Ply5cKvDLKx6fvERERERF9ujh97wsxf/58pKamYt26dXIJqXxWVlYYNWqU8D43NxczZsxA7dq1IRaLYWFhgUmTJiErK0vuuPwpWn///TeaNm0KNTU11KpVC5s3bxb6TJs2Debm5gCAcePGQSQSCesIvW9NoWnTpkEkEsm1RURE4JtvvoGenh60tLRQt25dTJo0Sdj/vjWlTpw4gVatWkFTUxN6enrw8PBAQkJCoedLSkpC//79oaenB11dXfj4+CA9Pf39N/Ydffv2xZEjR/Dq1Suh7ezZs7h58yb69u1boP+LFy8wduxY2NnZQUtLCzo6OnB3d0d8fLzQJzIyEl9//TUAwMfHR5gOln+dzs7OaNCgAc6fP4/WrVtDQ0NDuC/vrinl7e0NNTW1Atfv5uaGqlWr4sGDB0W+VkUo7Ov//Plz9OvXDzo6OtDT04O3tzfi4+Pfu17Y/fv30b17d2hpacHQ0BBjx46FRCIBkPc9YWhoCAAIDAwU7t20adPk2rZt21YgIQXkVTjNmDFDrkrqfYyNjQHkJaze5eHhAbFYjF27dsm1h4SEoGfPnkUan4iIiIiIqLJhUuoLceDAAdSqVQstWrQoUv+BAwfC398fjRs3xuLFi9GmTRvMmTMHvXv3LtA3KSkJ3333HTp06ICFCxeiatWq6N+/P65evQoA8PT0xOLFiwEAffr0wZYtW7BkyZJixX/16lV06dIFWVlZmD59OhYuXIhu3bohOjr6g8cdO3YMbm5uePLkCaZNm4YxY8YgJiYGLVu2RHJycoH+PXv2xJs3bzBnzhz07NkTGzduFKZ+FYWnpydEIhH27NkjtIWEhMDGxgaNGzcu0P/ff/9FaGgounTpgkWLFmHcuHG4fPky2rRpIySIbG1tMX36dADA4MGDsWXLFmzZsgWtW7cWxnn+/Dnc3d3RqFEjLFmyBG3bti00vuDgYBgaGsLb21tI3KxatQpHjx7FsmXLCkw7K29SqRRdu3bFH3/8AW9vb8yaNQsPHz6Et7d3of0lEgnc3NxQrVo1BAUFoU2bNli4cKEwDdXQ0BArVqwAAPTo0UO4d56enkhPT8eJEyfg7OyMGjVqFDvWZ8+e4dmzZ3j8+DFiY2MxevRoVKtWrdB1tDQ0NODh4YE//vhDaIuPj8fVq1cLTVaS4kgVvBERERERkeJw+t4XICUlBffv34eHh0eR+sfHx2PTpk0YOHAg1qxZAwAYOnQoqlevjqCgIJw8eVIu6XHjxg2cOnUKrVq1ApCX2DEzM8OGDRsQFBQEe3t76OjoYPTo0WjcuHGBaU9FERERgezsbBw5ckRu+tPHjBs3Dvr6+oiNjYW+vj4AoHv37nBwcEBAQAA2bdok19/BwQHr1q0T3j9//hzr1q3DvHnzinQ+bW1tdOnSBSEhIfjpp58glUqxfft2+Pr6Ftrfzs4OiYmJUFL6X364X79+sLGxwbp16zB16lQYGRnB3d0d/v7+cHJyKvT+PXr0CCtXrsSQIUM+GJ+enh7WrVsHNzc3zJ07F3379sXYsWPRvXv3En1dFC00NBSxsbFYsmSJULnn6+uLDh06FNo/MzMTvXr1wtSpUwEAP//8Mxo3box169bB19cXmpqa+O677+Dr6wt7e3u5a7x06RJyc3MLXWD8xYsXcmtd6ejoyE2FTEtLEyqw8n311Vc4evRogfZ8ffv2RdeuXXHv3j2YmZlh27ZtqFWrFpo3b17Eu0NERERERFS5sFLqC5CSkgIAhU5PKszhw4cBAGPGjJFr/+WXXwCgwNpT9erVExJSQF51St26dQs8taw08tei2rdvX5EXxn748CHi4uLQv39/ISEFAPb29ujQoYNwnW/7+eef5d63atUKz58/F+5hUfTt2xeRkZF49OgRTpw4gUePHr23GkYsFgsJKYlEgufPnwtTEy9cuFDkc4rFYvj4+BSpr6urK4YMGYLp06fD09MTampqWLVqVZHPVZbCwsKgoqIityaTkpIShg0b9t5jCvuaFeV7L/9rqqWlVWBfrVq1YGhoKGz79++X26+mpoaIiAhEREQgPDwcq1atgpaWFjp16oTExMRCz+fq6gp9fX1s374dMpkM27dvR58+fT4aJ5WOBDKFbkREREREpDislPoC6OjoAADevHlTpP537tyBkpISrKys5NqNjY2hp6eHO3fuyLXXrFmzwBhVq1ZV6MLNvXr1wtq1azFw4ED8+uuvaN++PTw9PfHdd9/JVRm9ex0AULdu3QL7bG1tER4ejrS0NGhqagrt715L1apVAQAvX74U7uPHdOrUCdra2tixYwfi4uLw9ddfw8rKqtDpglKpFMHBwfj9999x+/ZtYUodAFSrVq1I5wPyqnSKs6h5UFAQ9u3bh7i4OISEhKB69eofPebp06dy8WlpaRWa0CmNO3fuwMTEBBoaGnLt734v5lNTUytQmVTU7738JG1qamqBffv27UNOTg7i4+MxduzYAvuVlZXh4uIi19apUydYW1tj4sSJhS5or6Kigu+//x4hISFo2rQp7t27x6l75UAiy9sUNRYRkSI0CAiHkljj4x2JiCpA8tzOFR0CfUFYKfUF0NHRgampKa5cuVKs495daPx93rdIs6wIT6p63zneTn4AgLq6Ok6dOoVjx46hX79+uHTpEnr16oUOHToU6FsapbmWfGKxGJ6enti0aRP27t37wcTD7NmzMWbMGLRu3Rpbt25FeHg4IiIiUL9+/SJXhAF596c4Ll68iCdPngAALl++XKRjvv76a5iYmAhbUFBQsc5ZFkqzQLiVlRWqVKlS6L+LNm3awMXFBY6OjkUer0aNGqhbty5OnTr13j59+/ZFXFwcpk2bhoYNG6JevXolip2IiIiIiKgyYFLqC9GlSxfcunULsbGxH+1rbm4OqVSKmzdvyrU/fvwYr169Ep6kpwhVq1aVe1JdvnersYC8aVzt27fHokWLcO3aNcyaNQsnTpzAyZMnCx07P84bN24U2Hf9+nUYGBjIVUkpUt++fXHx4kW8efOm0MXh8/35559o27Yt1q1bh969e8PV1RUuLi4F7klRE4RFkZaWBh8fH9SrVw+DBw/G/Pnzcfbs2Y8et23bNmHKWkREBH788UeFxZTP3NwcDx8+LPDEw6SkpBKP+b57p6mpCWdnZ/z111+4f/9+icd/W25ubqGVV/m++eYb1KxZE5GRkaySKidc6JyIiIiI6NPFpNQXYvz48dDU1MTAgQPx+PHjAvtv3bqF4OBgAHnTkAAUeELeokWLAACdOyuunLN27dp4/fo1Ll26JLQ9fPgQe/fulev34sWLAsc2atQIAJCVlVXo2CYmJmjUqBE2bdokl+S5cuUKjh49KlxnWWjbti1mzJiB3377DcbGxu/tp6ysXKAKa9euXQWSJPnJs8ISeMU1YcIE3L17F5s2bcKiRYtgYWEBb2/v997HfC1btoSLi4uw1apVq9SxvMvNzQ05OTnCAvtA3hTH5cuXl3jM/KmAhd07f39/SCQS/PDDD4Umk4pTIZeYmIgbN26gYcOG7+0jEomwdOlSBAQEoF+/fkUem4iIiIiIqDLimlJfiNq1ayMkJAS9evWCra0tfvzxRzRo0ADZ2dmIiYnBrl270L9/fwBAw4YN4e3tjdWrV+PVq1do06YNzpw5g02bNqF79+5yT94rrd69e2PChAno0aMHRo4cifT0dKxYsQJ16tSRW+h7+vTpOHXqFDp37gxzc3M8efIEv//+O2rUqIFvvvnmveMvWLAA7u7ucHJywoABA5CRkYFly5ZBV1cX06ZNU9h1vEtJSQlTpkz5aL8uXbpg+vTp8PHxQYsWLXD58mXhqWxvq127NvT09LBy5Upoa2tDU1MTzZo1g6WlZbHiOnHiBH7//XcEBASgcePGAIANGzbA2dkZU6dOxfz584s13sckJSVh5syZBdodHBwKTW52794dTZs2xS+//IKkpCTY2Nhg//79QlKyJBVj6urqqFevHnbs2IE6depAX18fDRo0QIMGDdCqVSv89ttvGDFiBKytreHl5QUbGxtkZ2cjMTER27Ztg6qqaoHEYm5uLrZu3QogL2mWnJyMlStXQiqVIiAg4IPxeHh4FPlJmFR6UogggWIqDaUKGoeIiIiIiPIwKfUF6datGy5duoQFCxZg3759WLFiBcRiMezt7bFw4UK5J56tXbsWtWrVwsaNG7F3714YGxtj4sSJH/2Fu7iqVauGvXv3YsyYMRg/fjwsLS0xZ84c3Lx5Uy4p1a1bNyQnJ2P9+vV49uwZDAwM0KZNGwQGBkJXV/e947u4uCAsLAwBAQHw9/eHiooK2rRpg3nz5hU7oVMWJk2ahLS0NISEhGDHjh1o3LgxDh06hF9//VWun4qKCjZt2oSJEyfi559/Rm5uLjZs2FCsa3jz5g1++uknODg4YPLkyUJ7q1atMGrUKCxcuBCenp5o3ry5wq7vxo0bmDp1aoH2AQMGFJqUUlZWxqFDhzBq1Chs2rQJSkpK6NGjBwICAtCyZUuoqamVKI61a9dixIgRGD16NLKzsxEQEIAGDRoAAHx9feHk5ITFixdj165dePToEVRUVFC7dm14e3vD19cXtWvXlhsvKytLrtJJR0cHX3/9NbZs2YL27duXKEYqG1JZ3qaosYiIiIiISHFEsuLMTyEiqgChoaHo0aMH/v77b7Rs2bKiw6HPQEpKCnR1dXHuqhG0tBUzUz31jRRN6j/G69evi/w0TiKit+X/bDLz28mn7xHRJ4tP3yNFyP8/72OfnVkpRUSflIyMDLmnCUokEixbtgw6OjrClEOiopIocPqeosYhIiIiIqI8TEoR0SdlxIgRyMjIgJOTE7KysrBnzx7ExMRg9uzZcskqoqJgUoqIiIiI6NPFpBQRfVLatWuHhQsX4uDBg8jMzISVlRWWLVuG4cOHV3RoREREREREpECKWWiDiEhB+vbti/Pnz+P169fIysrC1atXmZCiEpPKRArd6PPQv39/dO/evdTjiEQihIaGlnoc+rCNGzdCT0+vosMgIiKiCsCkFBEREVUqwcHB2LhxY0WHUWLJyckQiUQf3D7X67OwsMCSJUvk2nr16oXExMQyO6ebmxuUlZVx9uxZhYwXGRkJkUiEV69eKWQ8IiKiLxmn7xERUaXFNaUqTnZ2NlRVVSvk3Lq6uhVy3neV9B6YmZnh4cOHwvugoCCEhYXh2LFjQtvb1yiRSCASiaCk9Hn+rVFdXb3M1gy8e/cuYmJiMHz4cKxfvx5ff/11mZyHiIiISuaLS0pJpVI8ePAA2traEIn4CwYRUUWSyWR48+YNTE1Ny+QXagmUIFFQUbBEIaNUXs7OzmjQoAGqVKmCrVu3ws7ODsuWLcO4ceMQFRUFTU1NuLq6YvHixTAwMBCOsbOzg7KyMjZt2gRVVVXMnDkTffv2xfDhw/Hnn3/CyMgIy5Ytg7u7O4C8BMzgwYNx4sQJPHr0CDVr1sTQoUMxatQoIZb+/fvj1atXwtQ7Z2dn2NvbQ01NDWvXroWqqip+/vlnTJs2TTjm5s2bGDBgAM6cOYNatWohODi4wDXeu3cPv/zyC44ePQolJSW0atUKwcHBsLCwkDvv119/jeXLl0MsFuP27dvFvpfKysowNjYW3mtpaaFKlSpC28aNG+Hn54fNmzfj119/RWJiIpKSkvD06VNMmjQJFy9eRE5ODho1aoTFixfLPblUJBJhzZo1OHToEMLDw/HVV19h4cKF6NatGwDg5cuXGD58OI4ePYrU1FTUqFEDkyZNgo+PDwBgwoQJ2Lt3L/777z8YGxvDy8sL/v7+UFFREc5x4MABTJ8+HZcvX4aWlhZatWqFvXv3wtnZGXfu3MHo0aMxevRoAHk/A/Kv5+3KoxUrViAoKAj37t2DpaUlpkyZgn79+hX5OvJt2LABXbp0ga+vL5o3b45FixbJJcCK+z2YnJyMtm3bAgCqVq0KAPD29v5sK9eIiIgq2heXlHrw4AHMzMwqOgwiInrLvXv3UKNGjYoOg0pp06ZN8PX1RXR0NF69eoV27dph4MCBWLx4MTIyMjBhwgT07NkTJ06ckDtm/PjxOHPmDHbs2AFfX1/s3bsXPXr0wKRJk7B48WL069cPd+/ehYaGBqRSKWrUqIFdu3ahWrVqiImJweDBg2FiYoKePXt+MLYxY8bg9OnTiI2NRf/+/dGyZUt06NABUqkUnp6eMDIywunTp/H69Wv4+fnJHZ+TkwM3Nzc4OTkhKioKVapUwcyZM9GxY0dcunRJqIg6fvw4dHR0EBERUSb3OF96ejrmzZuHtWvXolq1aqhevTr+/fdfeHt7Y9myZZDJZFi4cCE6deqEmzdvQltbWzg2MDAQ8+fPx4IFC7Bs2TJ4eXnhzp070NfXx9SpU3Ht2jUcOXIEBgYGSEpKQkZGhnCstrY2Nm7cCFNTU1y+fBmDBg2CtrY2xo8fDwA4dOgQevTogcmTJ2Pz5s3Izs7G4cOHAQB79uxBw4YNMXjwYAwaNOi917Z3716MGjUKS5YsgYuLCw4ePAgfHx/UqFFDSAh97DqAvITXhg0bsHz5ctjY2MDKygp//vmnXHILKN73oJmZGXbv3o1vv/0WN27cgI6OzgervLKyspCVlSW8T0lJKcqXl4iI6IshkslksooOojy9fv0aenp6uHPBAjpan2eZOxEAePZ6/y9fRJ+LXEkWoi4txqtXrxQ65SolJQW6uro4frkmNLUV87M+7Y0U7e3u4vXr19DR0VHImJWJs7MzUlJScOHCBQDAzJkzERUVhfDwcKHPf//9BzMzM9y4cQN16tSBs7MzJBIJoqKiAORVQenq6sLT0xObN28GADx69AgmJiaIjY1F8+bNCz338OHD8ejRI/z5558ACq+Uevs8ANC0aVO0a9cOc+fOxdGjR9G5c2fcuXMHpqamAICwsDC4u7tj79696N69O7Zu3YqZM2ciISFBqLTOzs6Gnp4eQkND4erqiv79+yMsLAx3795V6NTFadOmITQ0FHFxcQDyKqV8fHwQFxeHhg0bvvc4qVQKPT09hISEoEuXLgDyKoymTJmCGTNmAADS0tKgpaWFI0eOoGPHjujWrRsMDAywfv36IsUWFBSE7du349y5cwCAFi1aoFatWti6dWuh/S0sLODn5yeX9Hu3Uqply5aoX78+Vq9eLfTp2bMn0tLScOjQoSJdBwBERETAy8sLDx48QJUqVbBkyRKEhoYiMjJSGLck34ORkZFo27YtXr58+dEF2qdNm4bAwMAC7WZ+O6Ek1vjgsUREFSV5bueKDoEqgfzP4x/77PzFVUrlf5DU0VKCjoJ+USGqCFWUxRUdApHCcDp15eDo6Ci8jo+Px8mTJ6GlpVWg361bt1CnTh0AgL29vdCurKyMatWqwc7OTmgzMjICADx58kRoW758OdavX4+7d+8iIyMD2dnZaNSo0Qdje/s8AGBiYiKMmZCQADMzMyEhBQBOTk5y/ePj45GUlCRXcQQAmZmZuHXrlvDezs6uXNbSUlVVLXBNjx8/xpQpUxAZGYknT55AIpEgPT0dd+/elev39nGamprQ0dER7oWvry++/fZbXLhwAa6urujevTtatGgh9N+xYweWLl2KW7duITU1Fbm5uXIfNOPi4j5YBVUUCQkJGDx4sFxby5YtC0yp/NB1AMD69evRq1cvVKmS93G3T58+GDduHG7duoXatWsXOk5RvweLauLEiRgzZozwPiUlhRX7REREb/niklJERPTl4ELn5UtTU1N4nZqaiq5du2LevHkF+pmYmAiv316LCMhLUL7dlp+wlEqlAIDt27dj7NixWLhwIZycnKCtrY0FCxbg9OnTH4ytsPPkj1kUqampcHR0xLZt2wrsMzQ0FF6/fQ/Kkrq6eoFkrre3N54/f47g4GCYm5tDLBbDyckJ2dnZcv0+dC/c3d1x584dHD58GBEREWjfvj2GDRuGoKAgxMbGwsvLC4GBgXBzc4Ouri62b9+OhQsXysVVXj50HS9evMDevXuRk5ODFStWCH0kEgnWr1+PWbNmfXCcD30PFodYLIZYzD8iERERvQ+TUkREVGlJZEqQyBS00PkXNdm99Bo3bozdu3fDwsJCqFRRhOjoaLRo0QJDhw4V2t6uVCoJW1tb3Lt3Dw8fPhQSZv/8849cn8aNG2PHjh2oXr36Jzt9Mzo6Gr///js6deoEIG+ttmfPnhV7HENDQ3h7e8Pb2xutWrXCuHHjEBQUhJiYGJibm2Py5MlC3zt37sgda29vj+PHjwsLo79LVVUVEsmHHxtga2uL6OhoeHt7y11bvXr1inwN27ZtQ40aNYQpnPmOHj2KhQsXYvr06VBWVi7yeG/Lr4T72HUQERHRx3H+GhERESncsGHD8OLFC/Tp0wdnz57FrVu3EB4eDh8fn1L9Mm9tbY1z584hPDwciYmJmDp1Ks6ePVuqWF1cXFCnTh14e3sjPj4eUVFRcokXAPDy8oKBgQE8PDwQFRWF27dvIzIyEiNHjsR///1XqvMrirW1NbZs2YKEhAScPn0aXl5exa5c8vf3x759+5CUlISrV6/i4MGDsLW1Fca/e/cutm/fjlu3bmHp0qXYu3ev3PEBAQH4448/EBAQgISEBFy+fFmuWs7CwgKnTp3C/fv335swGzduHDZu3IgVK1bg5s2bWLRoEfbs2YOxY8cW+TrWrVuH7777Dg0aNJDbBgwYgGfPniEsLKxY9+Vt5ubmEIlEOHjwIJ4+fYrU1NQSj0VERPSlY1KKiIgqLSlEkEJJQRun7xWHqakpoqOjIZFI4OrqCjs7O/j5+UFPTw9KSiX/+DFkyBB4enqiV69eaNasGZ4/fy5XNVUSSkpK2Lt3LzIyMtC0aVMMHDhQbnoXAGhoaODUqVOoWbMmPD09YWtriwEDBiAzM/OTqZxat24dXr58icaNG6Nfv34YOXIkqlevXqwxVFVVMXHiRNjb26N169ZQVlbG9u3bAQDdunXD6NGjMXz4cDRq1AgxMTGYOnWq3PHOzs7YtWsX9u/fj0aNGqFdu3Y4c+aMsH/69OlITk5G7dq15aY9vq179+4IDg5GUFAQ6tevj1WrVmHDhg1wdnYu0jWcP38e8fHx+Pbbbwvs09XVRfv27bFu3boi3pGCvvrqKwQGBuLXX3+FkZERhg8fXuKxiIiIvnRf3NP38leAf5lYiwud02etY1evig6BqNRyJVk4eXGuwp9ol/+z/tClWtDULtkUnXelvZGgs/2/fPoeEZVY/s8mPn2PiD5lfPoeKQKfvkdERF88LnRORERERPTpYlKKiIgqLcUudP5FFRaTAkRFRcHd3b3QfRkZGR9c74nrFBEREdGXgEkpIiIiojLQpEkTxMXFFbrvY0kpIiIioi8Bk1JERFRp5S10rphpd1zonIpLXV0dVlZWFR0GERER0SeLK30TEREREREREVG5Y6UUERFVWlIoQaKgv79IwTWliIiIiIgUiUkpIiKqtLjQORERERHRp4vT94iIiIiIiIiIqNyxUoqIiCotKZQg5fQ9IiIiIqJPEpNSRERERETl6EqgG3R0dCo6DCIiogrHpBQREVVaEpkIEplIYWMREREREZHiMClFRESVlkSBT9+TcPoeEREREZFCcaFzIiIiIiIiIiIqd6yUIiKiSksqU4JUpqCFzmWslCIiIiIiUiRWShERERERERERUbljpRQREVVaXFOKiIiIiOjTxaQUERFVWlIo7ql5UoWMQkRERERE+ZiUIiIiIiIqRw0CwqEk1qjoMIiIPmnJcztXdAhUDpiUIiKiSksKJUgVNH1PUeMQEREREVEefsImIiIiIiIiIqJyx0opIiKqtCQyJUhkClroXEHjEBERERFRHialiIio0pJCBCkUtdC5YsYhIiIiIqI8/LMvERERERERERGVO1ZKERFRpcXpe0REREREny5+wiYiIiIiIiIionLHSikiIqq0JFCCREF/f1HUOERERERElIdJKSIiqrSkMhGkMgUtdK6gcYiIiIiIKA//7EtERERUyfXv3x/du3cv9TgikQihoaGlHudTl5ycDJFIhLi4uIoOhYiIqFJjpRQREVVaUgVO35Py7zj0GQsODoZMJqvoMD5rI0eORHR0NK5cuQJbW1smrIiIiBSAn7CJiIiIykF2dnaFnVtXVxd6enoVdv58FXkPClPceH766Sf06tWrjKIhIiL68jApRURElZZUpqTQjag4nJ2dMXz4cPj5+cHAwABubm64cuUK3N3doaWlBSMjI/Tr1w/Pnj2TO2bEiBHw8/ND1apVYWRkhDVr1iAtLQ0+Pj7Q1taGlZUVjhw5IhwjkUgwYMAAWFpaQl1dHXXr1kVwcLBcLO9O33N2dsbIkSMxfvx46Ovrw9jYGNOmTZM75ubNm2jdujXU1NRQr149REREFLjGe/fuoWfPntDT04O+vj48PDyQnJxc4LyzZs2Cqakp6tatW6p7mpWVhQkTJsDMzAxisRhWVlZYt25dse/Du/GcOXMGDg4OUFNTQ5MmTXDx4sUC5166dCmGDRuGWrVqleoaiIiI6H/4CZuIiCotCUQK3YiKa9OmTVBVVUV0dDTmzp2Ldu3awcHBAefOnUNYWBgeP36Mnj17FjjGwMAAZ86cwYgRI+Dr64vvv/8eLVq0wIULF+Dq6op+/fohPT0dACCVSlGjRg3s2rUL165dg7+/PyZNmoSdO3d+NDZNTU2cPn0a8+fPx/Tp04XEk1QqhaenJ1RVVXH69GmsXLkSEyZMkDs+JycHbm5u0NbWRlRUFKKjo6GlpYWOHTvKVSAdP34cN27cQEREBA4ePFiq+/njjz/ijz/+wNKlS5GQkIBVq1ZBS0urWPfh3XhSU1PRpUsX1KtXD+fPn8e0adMwduzYUsVJRERERcM1pYiIiIjKiLW1NebPnw8AmDlzJhwcHDB79mxh//r162FmZobExETUqVMHANCwYUNMmTIFADBx4kTMnTsXBgYGGDRoEADA398fK1aswKVLl9C8eXOoqKggMDBQGNPS0hKxsbHYuXNngYTX2+zt7REQECDE+dtvv+H48ePo0KEDjh07huvXryM8PBympqYAgNmzZ8Pd3V04fseOHZBKpVi7di1Eoryk7YYNG6Cnp4fIyEi4uroCADQ1NbF27VqoqqqW6l4mJiZi586diIiIgIuLCwDIVS0V9T68G8/q1ashlUqxbt06qKmpoX79+vjvv//g6+tbqniBvMqurKws4X1KSkqpxyQiIqpMWClFRESVVkVO35NIJJg6daowlah27dqYMWOG3GLTMpkM/v7+MDExgbq6OlxcXHDz5k25cV68eAEvLy/o6OhAT08PAwYMQGpqqlyfS5cuoVWrVlBTU4OZmZmQBHnbrl27YGNjAzU1NdjZ2eHw4cPFuh4qGUdHR+F1fHw8Tp48CS0tLWGzsbEBANy6dUvoZ29vL7xWVlZGtWrVYGdnJ7QZGRkBAJ48eSK0LV++HI6OjjA0NISWlhZWr16Nu3fvfjC2t88DACYmJsKYCQkJMDMzExJSAODk5CTXPz4+HklJSdDW1hauR19fH5mZmXLXY2dnV+qEFADExcVBWVkZbdq0eW+fotyHd+NJSEiAvb091NTUhLZ3r7Wk5syZA11dXWEzMzNTyLhERESVBSuliIiIysC8efOwYsUKbNq0CfXr18e5c+fg4+MDXV1djBw5EgAwf/58LF26FJs2bYKlpSWmTp0KNzc3XLt2TfgF2cvLCw8fPkRERARycnLg4+ODwYMHIyQkBEBe5YWrqytcXFywcuVKXL58GT/99BP09PQwePBgAEBMTAz69OmDOXPmoEuXLggJCUH37t1x4cIFNGjQoGJu0BdCU1NTeJ2amoquXbti3rx5BfqZmJgIr1VUVOT2iUQiubb8qiSpVAoA2L59O8aOHYuFCxfCyckJ2traWLBgAU6fPv3B2Ao7T/6YRZGamgpHR0ds27atwD5DQ0Ph9dv3oDTU1dU/uL+o90FR8RTFxIkTMWbMGOF9SkoKE1NERERvYVKKiIgqLQmgsLWgJMXsHxMTAw8PD3Tu3BkAYGFhgT/++ANnzpwBkFcltWTJEkyZMgUeHh4AgM2bN8PIyAihoaHo3bs3EhISEBYWhrNnz6JJkyYAgGXLlqFTp04ICgqCqakptm3bhuzsbKxfvx6qqqqoX78+4uLisGjRIiEpFRwcjI4dO2LcuHEAgBkzZiAiIgK//fYbVq5cqYC7Q0XRuHFj7N69GxYWFqhSRXEfwaKjo9GiRQsMHTpUaHu7UqkkbG1tce/ePTx8+FBImP3zzz9yfRo3bowdO3agevXq0NHRKdX5isLOzg5SqRR//fWXMH3vbSW9D7a2ttiyZQsyMzOFZPC711pSYrEYYrFYIWMRERFVRpy+R0RElVZFTt9r0aIFjh8/jsTERAB5U53+/vtvYU2e27dv49GjR3K/XOvq6qJZs2aIjY0FAMTGxkJPT09ISAGAi4sLlJSUhOqP2NhYtG7dWm46kpubG27cuIGXL18Kfd79Jd7NzU04D5WPYcOG4cWLF+jTpw/Onj2LW7duITw8HD4+PpBIipv2/B9ra2ucO3cO4eHhSExMxNSpU3H27NlSxeri4oI6derA29sb8fHxiIqKwuTJk+X6eHl5wcDAAB4eHoiKisLt27cRGRmJkSNH4r///ivV+QtjYWEBb29v/PTTTwgNDRXOl7+QeUnvQ9++fSESiTBo0CBcu3YNhw8fRlBQUIF+SUlJiIuLw6NHj5CRkYG4uDjExcXJLepORERExcOkFBERUTGkpKTIbW8vYvy2X3/9Fb1794aNjQ1UVFTg4OAAPz8/eHl5AQAePXoE4H/rA+UzMjIS9j169AjVq1eX21+lShXo6+vL9SlsjLfP8b4++fupfJiamiI6OhoSiQSurq6ws7ODn58f9PT0oKRU8o9kQ4YMgaenJ3r16oVmzZrh+fPnctVCJaGkpIS9e/ciIyMDTZs2xcCBAzFr1iy5PhoaGjh16hRq1qwJT09P2NraYsCAAcjMzCyzyqkVK1bgu+++w9ChQ2FjY4NBgwYhLS0NQMnvg5aWFg4cOIDLly/DwcEBkydPLnSK5cCBA+Hg4IBVq1YhMTERDg4OcHBwwIMHDxR+nURERF8KTt8jIqJKSyJTgqSYFU4fGgtAgfVgAgICMG3atAL9d+7ciW3btiEkJESYUufn5wdTU1N4e3srJCb6tEVGRhZos7a2xp49e4p1THJycoG2txfMF4vF2LBhAzZs2CDXZ86cOcLrjRs3fvQ8oaGhcu/r1KmDqKio954XAIyNjbFp06YCY73vvKWlpqaGRYsWYdGiRQX2leQ+5GvevDni4uLk2t691sLuGREREZUOk1JERFRpySCCVEFrSsn+f5x79+7JVYG8b72YcePGCdVSQN56OHfu3MGcOXPg7e0NY2NjAMDjx4/lFrl+/PgxGjVqBCDvF/63n7AGALm5uXjx4oVwvLGxMR4/fizXJ//9x/rk7yciIiIiqgicvkdERFQMOjo6ctv7klLp6ekFpmQpKysLTzeztLSEsbExjh8/LuxPSUnB6dOnhcfROzk54dWrVzh//rzQ58SJE5BKpWjWrJnQ59SpU8jJyRH6REREoG7duqhatarQ5+3z5PdR1GPviYoqKioKWlpahW7Kysrv3aelpVXRoRMREVEZYKUUERFVWmUxfa+ounbtilmzZqFmzZqoX78+Ll68iEWLFuGnn34CAIhEIvj5+WHmzJmwtraGpaUlpk6dClNTU3Tv3h1A3lPBOnbsiEGDBmHlypXIycnB8OHD0bt3b5iamgLIW6Q5MDAQAwYMwIQJE3DlyhUEBwdj8eLFQiyjRo1CmzZtsHDhQnTu3Bnbt2/HuXPnsHr1aoXcG6KiatKkSYFpcvkyMjKgrq5evgERERFRhWJSioiIqAwsW7YMU6dOxdChQ/HkyROYmppiyJAh8Pf3F/qMHz8eaWlpGDx4MF69eoVvvvkGYWFhwmPpAWDbtm0YPnw42rdvDyUlJXz77bdYunSpsF9XVxdHjx7FsGHD4OjoCAMDA/j7+2Pw4MFCnxYtWiAkJARTpkzBpEmTYG1tjdDQUDRo0KB8bgbR/1NXV4eVlVVFh0FERESfCJHs3VUcK7mUlBTo6uriZWIt6Ghz9iJ9vjp29aroEIhKLVeShZMX5+L169cKfVpX/s/6X6K7QKylopAxs1JzsLDlQYXHSkRfjvyfTWZ+O6Ek1qjocIiIPmnJcztXdAhUCvn/533sszMrpYiIqNKSQAkSBS2fqKhxiIiIiIgoDz9hExERERERERFRuWOlFBERVVpSmQhSmUhhYxERERERkeKwUoqIiIiIiIiIiModK6WIiKjSkkIJUgX9/UVR4xARXQl04wMTiIiIwKQUERFVYhKZCBIFTbtT1DhERERERJSHf/YlIiIiIiIiIqJyx0opIiKqtLjQORERERHRp4uVUkREREREREREVO5YKUVERJWWTKYEqUwxf3+RKWgcIiIiIiLKw6QUERFVWhKIIIGCFjpX0DhERERERJSHf/YlIiIiIiIiIqJyx0opIiKqtKQyxS1QLpUpZBgiIjQICIeSWKOiw6BPVPLczhUdAhFRuWGlFBERERERERERlTtWShERUaUlVeBC54oah4iIiIiI8jApRURElZYUIkgVtEC5osYhIiIiIqI8/LMvERERERERERGVO1ZKERFRpSWRiSBR0ELnihqHiIiIiIjysFKKiIiIiIiIiIjKHSuliIio0uJC50REREREny4mpYiIqNKSQgSpgqbdcaFzIiIiIiLF4p99iYiIiIiIiIio3LFSioiIKi0ZRAqrcJKxUoqIiIiISKFYKUVERERfnP79+6N79+6lHkckEiE0NLTU49CHbdy4EXp6ehUdBhERESkYk1JERFRpSWUihW5UeQQHB2Pjxo0VHUaJJScnQyQSfXD7XK/PwsICS5YskWvr1asXEhMTFXqed++htrY26tevj2HDhuHmzZtCP2dn5w/eZ2dnZ4XGRURE9CXh9D0iIqq0+PS9T1t2djZUVVUr5Ny6uroVct53lfQemJmZ4eHDh8L7oKAghIWF4dixY0Lb29cokUggEomgpPR5fh+rq6tDXV29TMY+duwY6tevj/T0dFy+fBnBwcFo2LAhDhw4gPbt22PPnj3Izs4GANy7dw9NmzYVjgFQYd/DRERElcHn+cmEiIiIPjvOzs4YPnw4/Pz8YGBgADc3N1y5cgXu7u7Q0tKCkZER+vXrh2fPnskdM2LECPj5+aFq1aowMjLCmjVrkJaWBh8fH2hra8PKygpHjhwRjpFIJBgwYAAsLS2hrq6OunXrIjg4WC6Wd6fvOTs7Y+TIkRg/fjz09fVhbGyMadOmyR1z8+ZNtG7dGmpqaqhXrx4iIiIKXOO9e/fQs2dP6OnpQV9fHx4eHkhOTi5w3lmzZsHU1BR169Yt0b1UVlaGsbGxsGlpaaFKlSrC+7CwMJiYmGD//v2oV68exGIx7t69i7Nnz6JDhw4wMDCArq4u2rRpgwsXLsiNLRKJsHbtWvTo0QMaGhqwtrbG/v37hf0vX76El5cXDA0Noa6uDmtra2zYsEHYP2HCBNSpUwcaGhqoVasWpk6dipycHLlzHDhwAF9//TXU1NRgYGCAHj16CF+HO3fuYPTo0UIlElD49L0VK1agdu3aUFVVRd26dbFly5ZiXUe+atWqwdjYGLVq1YKHhweOHTuGZs2aYcCAAZBIJML3g7GxMQwNDeWOMTY2hr6+fjG/ekRERJSPSSkiIqq0OH3v07Np0yaoqqoiOjoac+fORbt27eDg4IBz584hLCwMjx8/Rs+ePQscY2BggDNnzmDEiBHw9fXF999/jxYtWuDChQtwdXVFv379kJ6eDgCQSqWoUaMGdu3ahWvXrsHf3x+TJk3Czp07PxqbpqYmTp8+jfnz52P69OlC4kkqlcLT0xOqqqo4ffo0Vq5ciQkTJsgdn5OTAzc3N2hrayMqKgrR0dHQ0tJCx44dhUobADh+/Dhu3LiBiIgIHDx4UBG3tVDp6emYN28e1q5di6tXr6J69ep48+YNvL298ffff+Off/6BtbU1OnXqhDdv3sgdGxgYiJ49e+LSpUvo1KkTvLy88OLFCwDA1KlTce3aNRw5cgQJCQlYsWIFDAwMhGO1tbWxceNGXLt2DcHBwVizZg0WL14s7D906BB69OiBTp064eLFizh+/DiaNm0KANizZw9q1KiB6dOn4+HDh3LVYG/bu3cvRo0ahV9++QVXrlzBkCFD4OPjg5MnTxb5Ot5HSUkJo0aNwp07d3D+/Pmi3/BCZGVlISUlRW4jIiKi/+H0PSIiIio31tbWmD9/PgBg5syZcHBwwOzZs4X969evh5mZGRITE1GnTh0AQMOGDTFlyhQAwMSJEzF37lwYGBhg0KBBAAB/f3+sWLECly5dQvPmzaGiooLAwEBhTEtLS8TGxmLnzp0FEl5vs7e3R0BAgBDnb7/9huPHj6NDhw44duwYrl+/jvDwcJiamgIAZs+eDXd3d+H4HTt2QCqVYu3atUKFz4YNG6Cnp4fIyEi4uroCADQ1NbF27doyn/aVk5OD33//HQ0bNhTa2rVrJ9dn9erV0NPTw19//YUuXboI7f3790efPn0A5F3n0qVLcebMGXTs2BF3796Fg4MDmjRpAiBvDai35X+t8veNHTsW27dvx/jx4wEAs2bNQu/eveW+Rvkx6uvrQ1lZGdra2jA2Nn7vtQUFBaF///4YOnQoAGDMmDH4559/EBQUhLZt2xbpOj7ExsYGQN66U/kJs5KYM2eO3HUSERGRPFZKERFRpSWFSKEblZ6jo6PwOj4+HidPnoSWlpaw5ScDbt26JfSzt7cXXisrK6NatWqws7MT2oyMjAAAT548EdqWL18OR0dHGBoaQktLC6tXr8bdu3c/GNvb5wEAExMTYcyEhASYmZkJCSkAcHJykusfHx+PpKQkaGtrC9ejr6+PzMxMueuxs7Mrl3WIVFVVC1zT48ePMWjQIFhbW0NXVxc6OjpITU0tcG/ePk5TUxM6OjrCvfD19cX27dvRqFEjjB8/HjExMXLH7tixAy1bthSmFU6ZMkVu/Li4OLRv375U15aQkICWLVvKtbVs2RIJCQlFvo4PkclkACAkF0tq4sSJeP36tbDdu3evVOMRERFVNqyUIiKiSkuR0+44fU8xNDU1hdepqano2rUr5s2bV6CfiYmJ8FpFRUVun0gkkmvLTxxIpVIAwPbt2zF27FgsXLgQTk5O0NbWxoIFC3D69OkPxlbYefLHLIrU1FQ4Ojpi27ZtBfblr0UEyN+DsqSurl4gqeLt7Y3nz58jODgY5ubmEIvFcHJykpteCHz4Xri7u+POnTs4fPgwIiIi0L59ewwbNgxBQUGIjY2Fl5cXAgMD4ebmBl1dXWzfvh0LFy6Ui6u8lPRrmp/csrS0LNX5xWIxxGJxqcYgIiKqzJiUIgBAeqoSNs03QcwRXbx6XgW162fAd8Z/qNsoAwCQkaaEdbNMEBuui5SXVWBslg2PAU/R5cfnAICUl8rYEmSMC39p48kDVejq56JFx9fwHv8Qmjp5H/6O7tDHwtE1Cz3/jktXoGeQiyunNbFulgnu3VJDVoYSqn+Vjc79nsNz8NPyuRH0WWtQ/wm+87wG69ovUa1aBgJntULsP2bC/l/8YtGh/W25Y86dN8GUaf+b6rFp7T4YGaXJ9Vm/qSF2/llfeN/qmzvo/f1VfPXVG7x+LcaBg3Xw5956wv769Z7gJ+84mNVIgVgswZOnmjgcZoW9+2wUfclEn7XGjRtj9+7dsLCwQJUqivtIEh0djRYtWghTuwD5yquSsLW1xb179/Dw4UMhYfbPP//I9WncuDF27NiB6tWrQ0dHp1TnKyvR0dH4/fff0alTJwB5C7O/vbB8URkaGsLb2xve3t5o1aoVxo0bh6CgIMTExMDc3ByTJ08W+t65c0fuWHt7exw/fhw+Pj6Fjq2qqgqJRPLB89va2iI6Ohre3t5y11avXr0PHFU0UqkUS5cuhaWlJRwcHEo9HhEREb0fk1IEAFj8ixmSb6hh/LI70DfKwYnd+vi1lxXWRF6HgUkOVk0zRVy0NsYvuwsjs2xc+EsbyybWQDWjHDi5peDFYxU8f6yCQf4PULNOJp78p4qlv9bA88cqmLomGQDQpttLNGkrv8BnkF9N5GQpQc8gFwCgpiFFN59nsKyXCTUNKa6e0UTw+BpQ05Ci0w/Py/u20GdGTS0Xt29XxdGI2vCfHFVon7PnTbBoSXPhfU6OcoE+m7fa4Ui4lfA+PeN/f2lv4vgAE36Jwe+rmuDCRRPUNHuNUcPPICtbGQcO5T1FKzOzCg4cqoPbyXrIzKyC+vWeYuSwM8jMrCI3LpU9Vkp92oYNG4Y1a9agT58+wlPvkpKSsH37dqxduxbKygX/fRaFtbU1Nm/ejPDwcFhaWmLLli04e/ZsqapeXFxcUKdOHXh7e2PBggVISUmRS7wAgJeXFxYsWAAPDw9Mnz4dNWrUwJ07d7Bnzx6MHz8eNWrUKPH5FcXa2hpbtmxBkyZNkJKSgnHjxhW7csnf3x+Ojo6oX78+srKycPDgQdja2grj3717F9u3b8fXX3+NQ4cOYe/evXLHBwQEoH379qhduzZ69+6N3NxcHD58WFg43sLCAqdOnULv3r0hFovlFlHPN27cOPTs2RMODg5wcXHBgQMHsGfPHhw7dqzY9+T58+d49OgR0tPTceXKFSxZsgRnzpzBoUOHSvw9SEREREXzSawptXz5clhYWEBNTQ3NmjXDmTNnPth/165dsLGxgZqaGuzs7HD48OFyirRyysoQ4e/Dehg45SHsmqfhK8ts9Bv7CKYWWTi4uRoA4No5TXT4/gUatkiFsVk2Ov3wHLXqZeBGnAYAwMImE/5rk9HcNQWmFtlo9E0q+k94iNMROpDk5ZsgVpdBv3qusCkpyxAfrQW3Pv9LNlnZZaBtj1ewqJsJY7NstP/2JZo4v8GV0+Uz1YE+b+fOm2LT1oaIeas66l05Ocp4+Upd2FLTCq7rkp6hItcnK+t/+fv2bW8j9p8aOBxmjUePtXDm3FfY8Wc99Pw2AUDeGiS3/tVH5CkL3Lmrh8dPtHAi0hLnL5igQf2Pr2NC9CUxNTVFdHQ0JBIJXF1dYWdnBz8/P+jp6UFJqeQfUYYMGQJPT0/06tULzZo1w/Pnz+WqpkpCSUkJe/fuRUZGBpo2bYqBAwdi1qxZcn00NDRw6tQp1KxZE56enrC1tcWAAQOQmZn5yVROrVu3Di9fvkTjxo3Rr18/jBw5EtWrVy/WGKqqqpg4cSLs7e3RunVrKCsrY/v27QCAbt26YfTo0Rg+fDgaNWqEmJgYTJ06Ve54Z2dn7Nq1C/v370ejRo3Qrl07uc9+06dPR3JyMmrXri037fFt3bt3R3BwMIKCglC/fn2sWrUKGzZsgLOzc/FuCPISjiYmJrCzs8Ovv/4KW1tbXLp0SW7BdCIiIiobIln+So4VZMeOHfjxxx+xcuVKNGvWDEuWLMGuXbtw48aNQj8kxcTEoHXr1pgzZw66dOmCkJAQzJs3DxcuXECDBg0+er6UlBTo6uriZWIt6Gh/Ejm5CpeeqoQedewxd0cSHFqlCu1jPKygXAVYsDsJS8bVwK0rGghYfxvVjHMQH6OFaf0tMWPLv7BrnlbouEe26WPDHFPsvHKl0P1/rjREyBJj/HHxCsTqhX8bJl1Wx5QfasF7/EO4e334Ec5fmo5dvSo6hE9a2IGQQqfvOTX7D7m5SkhNVUXcJSNs2toQb978b72PTWv3QUVVgirKUjx5qonIv8yxZ58NpNK8nxdTJkYhK0sZCxa1EI7p6JoEvxFn4D2gGx4/0SoQS+1aLzBjWiQ2b7VH2FFWSr0tV5KFkxfn4vXr1wr9pT3/Z73bkcFQ0VTMgtI5adkId1+t8FiJ6MuR/7PJzG8nlMQaFR0OfaKS53au6BCIiEot//+8j312rvDpe4sWLcKgQYOEdQVWrlyJQ4cOYf369fj1118L9A8ODkbHjh0xbtw4AMCMGTMQERGB3377DStXrizX2CsLDS0pbB3TELLEGDWtk6FnmIvI0KpIOK8JU4ssAMDQmfcRPN4MXo71oVxFBiUlGUYtuPfehNTr58oIWWIM9x/ev05F+B/V0LbHy0ITUl6O9fD6eRVIckX44ZdHTEiRQpw7b4LoGDM8eqwFE5M36N8vHjOnncToca5C0mnfgTpIuqWPN6mqsLV5Bh/vOOjrZ2D1urwnhp2/YIIhA88jwv4R4i8bwdTkDTy7XwcA6FfNkEtKbdmwF7q6WVBWkmHbHw2YkKoAnL5HRERERPTpqtCkVHZ2Ns6fP4+JEycKbUpKSnBxcUFsbGyhx8TGxmLMmDFybW5ubggNDS20f1ZWFrKysoT3KSkphfb70o1fdgeLxtRE38YNoKQsg5VdOpy7v8TNS3l/xdu33gDXz2sgcOO/qF4jG5f/0cLySXlrSjVunSo3VtobJUz9sRZq1slEv18eFXq+a+c0cPdm3hpWhVm4NwkZaUpIuKCB9bNNYWqRhbY9Xin0munL81eUhfA6+Y4ebt+uio1r98O+wRPEXTIGAOzZZyv0uZ1cFbm5Shg57Aw2bGqEnFxlHAmvDRPjNwj0/wtVqkiRnq6C0P110c/rcoGkxdhfO0BdLRc2dZ/hJ+84PHiojchTFiAiyhcVFQV3d/dC92VkZHxwvafU1NT37iMiIiL6HFRoUurZs2eQSCQwMjKSazcyMsL169cLPebRo0eF9n/0qPDkx5w5cxAYGKiYgCsxU4tsBO1JQma6EtLeKKGaUS5mDTGHiXkWsjJE2DjXBP7rktHMJS+pV6teJv69qo4/V1aXS0qlpyphct/aUNeUImDdbVRRKfx8YSHVULt+OqztMwrdb1wz79HUlraZePVUBVsXGjMpRQr36LEWXr0Ww9T0jZCUeteNxGqoUkUGI6M0/HdfB4AI6zc5YOOWhqiql4nXKWI0avg4b7xH8lP3Hj/Oe598Rw9V9TLxQ5/LTEqVMxkAKRRT4VShc92p0mrSpAni4uIK3fexpBQRERHR567Cp++VtYkTJ8pVVqWkpMDM7P2LIH/p1DSkUNOQ4s0rZZz/SwcDpzxAbq4IuTlKUFKS/5VMSVkGmfR/79Pe5CWkVFRlCNz4L1TVCv8VLiNNCacO6MFn4sMixSSVAjnZXP+LFM+gWjp0tLPw4sX7f+mrZfkSEokIr16pybVLpUp4/iKvktC5dTKuJRjgdYpaYUMAAERKMqioSN+7n4i+TOrq6rCy4tReIiIi+jJVaFLKwMAAysrKePz4sVz748ePYWxceNWCsbFxsfqLxWKIxeJC99H/nIvUhkwGmNXOwv3bqlg74yuYWWXCtddzVFEB7J1SsWaGKVTV7sOoRjYuxWrh2J/6GBxwH0BeQmpSn9rIylDC+GW3kZ6qjPT/L6DSrZaLt5+o/Nc+PUgkIrT/9mWBOPZvMED1r7JhZpUJALj8jxZ2r6wOjwFPy/we0OdPTS0Hpib/q9wzNkpDLcuXeJOqijdvVPFDnyv4O8YML1+qwcQ4FQN8LuLBQ22cv2ACALCt+xR16z5H/CUjZGSowNbmKYYMvIATkRbCU/p0dDLxTYt7uHSlOlRVpHB1uYVWLe9h3MT2wnm7dkrEk6cauPdf3oJ+dg2e4tseCdh/oG453g0CuKYUEREREdGnrEKTUqqqqnB0dMTx48fRvXt3AIBUKsXx48cxfPjwQo9xcnLC8ePH4efnJ7RFRETAycmpHCKuvNJSlLFhjgmePVSBtp4ELTu9gs+vD4XpdxNXJGP9bBPMG14Tb15VQfWvstF/wkN0+fE5ACDpsgauX9AEAPi0qCc39qbT12Bsli28D/ujGlq6v4KWrqRAHDIpsH6OCR7dVYVyFcDUPAs/TX6Azv2el9GVU2VSx+oF5s85LrwfMvACACDiuCWW/f41LC1ewqXdv9DUzMGLF+o4f9EYm7fZIyc3L2uak6uMNq3u4Ic+l6GiIsWjx5rYu88Ge0Jt5M7Tof2/GPTTRYhEMiRcN8D4Se2ReNNA2C9SksHHOx7GRqmQSJTw8JEW1m90wOEwVkOUNyaliIiIiIg+XSKZTFahy2Ts2LED3t7eWLVqFZo2bYolS5Zg586duH79OoyMjPDjjz/iq6++wpw5cwAAMTExaNOmDebOnYvOnTtj+/btmD17Ni5cuIAGDRp89Hz5jyV8mVgLOtqcEkafr45dvSo6BKJSy5Vk4eTFuR99VGxx5f+sdz7oiyqaiqmWzU3LQmSXFQqPlYi+HPk/m8z8dkJJrFHR4dAnKnlu54oOgYio1PL/z/vYZ+cKX1OqV69eePr0Kfz9/fHo0SM0atQIYWFhwmLmd+/ehZLS/5JHLVq0QEhICKZMmYJJkybB2toaoaGhRUpIERHRl4WVUkREREREn64KT0oBwPDhw987XS8yMrJA2/fff4/vv/++jKMiIiIiIiIiIqKy8kkkpYiIiMoCK6WI6FN0JdCN04CJiIjApBQREVViMpkIMgUlkxQ1DhERERER5eFK30REREREREREVO5YKUVERJWWFCJIoaDpewoah4iIiIiI8jApRURElRbXlCIiIiIi+nRx+h4REREREREREZU7VkoREVGlxYXOiYiIiIg+XayUIiIiIiIiIiKicsdKKSIiqrS4phQRfYoaBIRDSaxR0WHQO5Lndq7oEIiIvjhMShERUaXF6XtERERERJ8uTt8jIiIiIiIiIqJyx0opIiKqtGQKnL7HSikiIiIiIsVipRQREREREREREZU7VkoREVGlJQMgkyluLCIiIiIiUhwmpYiIqNKSQgQRFPT0PQWNQ0REREREeTh9j4iIiIiIiIiIyh0rpYiIqNKSyUQKW6CcC50TERERESkWK6WIiIiIiIiIiKjcMSlFRESVllQmUuhG9Lnq378/unfvXupxRCIRQkNDSz3Opy45ORkikQhxcXEVHQoREVGlxqQUERFVWjKZYjeiz1VwcDA2btxY0WF8tuLj49GnTx+YmZlBXV0dtra2CA4OruiwiIiIPntcU4qIiIioHGRnZ0NVVbVCzq2rq1sh531XRd6DwhQ1nvPnz6N69erYunUrzMzMEBMTg8GDB0NZWRnDhw8vh0iJiIgqJ1ZKERFRpZW/0LmiNqLicHZ2xvDhw+Hn5wcDAwO4ubnhypUrcHd3h5aWFoyMjNCvXz88e/ZM7pgRI0bAz88PVatWhZGREdasWYO0tDT4+PhAW1sbVlZWOHLkiHCMRCLBgAEDYGlpCXV1ddStW7dAFc+70/ecnZ0xcuRIjB8/Hvr6+jA2Nsa0adPkjrl58yZat24NNTU11KtXDxEREQWu8d69e+jZsyf09PSgr68PDw8PJCcnFzjvrFmzYGpqirp165bqnmZlZWHChAkwMzODWCyGlZUV1q1bV+z78G48Z86cgYODA9TU1NCkSRNcvHhR7riffvoJwcHBaNOmDWrVqoUffvgBPj4+2LNnT6muh4iI6EvHpBQRERFRGdm0aRNUVVURHR2NuXPnol27dnBwcMC5c+cQFhaGx48fo2fPngWOMTAwwJkzZzBixAj4+vri+++/R4sWLXDhwgW4urqiX79+SE9PBwBIpVLUqFEDu3btwrVr1+Dv749JkyZh586dH41NU1MTp0+fxvz58zF9+nQh8SSVSuHp6QlVVVWcPn0aK1euxIQJE+SOz8nJgZubG7S1tREVFYXo6GhoaWmhY8eOyM7OFvodP34cN27cQEREBA4ePFiq+/njjz/ijz/+wNKlS5GQkIBVq1ZBS0urWPfh3XhSU1PRpUsX1KtXD+fPn8e0adMwduzYj8by+vVr6Ovrf7BPVlYWUlJS5DYiIiL6H07fIyKiSkuRFU6slKKSsLa2xvz58wEAM2fOhIODA2bPni3sX79+PczMzJCYmIg6deoAABo2bIgpU6YAACZOnIi5c+fCwMAAgwYNAgD4+/tjxYoVuHTpEpo3bw4VFRUEBgYKY1paWiI2NhY7d+4skPB6m729PQICAoQ4f/vtNxw/fhwdOnTAsWPHcP36dYSHh8PU1BQAMHv2bLi7uwvH79ixA1KpFGvXroVIlPfvY8OGDdDT00NkZCRcXV0BAJqamli7dm2pp+0lJiZi586diIiIgIuLCwCgVq1awv6i3od341m9ejWkUinWrVsHNTU11K9fH//99x98fX3fG0tMTAx27NiBQ4cOfTDmOXPmyMVERERE8piUIiKiSksqE0GkoGQSn75HJeHo6Ci8jo+Px8mTJ4XKnrfdunVLSErZ29sL7crKyqhWrRrs7OyENiMjIwDAkydPhLbly5dj/fr1uHv3LjIyMpCdnY1GjRp9MLa3zwMAJiYmwpgJCQkwMzMTElIA4OTkJNc/Pj4eSUlJ0NbWlmvPzMzErVu3hPd2dnYKWUcqLi4OysrKaNOmzXv7FOU+vBtPQkIC7O3toaamJrS9e61vu3LlCjw8PBAQECAk3t5n4sSJGDNmjPA+JSUFZmZmHzyGiIjoS8KkFBEREVEZ0dTUFF6npqaia9eumDdvXoF+JiYmwmsVFRW5fSKRSK4tvypJKpUCALZv346xY8di4cKFcHJygra2NhYsWIDTp09/MLbCzpM/ZlGkpqbC0dER27ZtK7DP0NBQeP32PSgNdXX1D+4v6n0oTTzXrl1D+/btMXjwYKGa7UPEYjHEYnGJz0dERFTZMSlFRESVlkyWtylqLKLSaNy4MXbv3g0LCwtUqaK4j2DR0dFo0aIFhg4dKrS9XalUEra2trh37x4ePnwoJMz++ecfuT6NGzfGjh07UL16dejo6JTqfEVhZ2cHqVSKv/76S5i+97aS3gdbW1ts2bIFmZmZQrXUu9cKAFevXkW7du3g7e2NWbNmleJKiIiIKB8XOiciIiIqB8OGDcOLFy/Qp08fnD17Frdu3UJ4eDh8fHwgkUhKPK61tTXOnTuH8PBwJCYmYurUqTh79mypYnVxcUGdOnXg7e2N+Ph4REVFYfLkyXJ9vLy8YGBgAA8PD0RFReH27duIjIzEyJEj8d9//5Xq/IWxsLCAt7c3fvrpJ4SGhgrny1/IvKT3oW/fvhCJRBg0aBCuXbuGw4cPIygoSK7PlStX0LZtW7i6umLMmDF49OgRHj16hKdPnyr8OomIiL4kTEoREVGllVcpJVLQVtFXQ587U1NTREdHQyKRwNXVFXZ2dvDz84Oenh6UlEr+kWzIkCHw9PREr1690KxZMzx//lyuWqgklJSUsHfvXmRkZKBp06YYOHBggeogDQ0NnDp1CjVr1oSnpydsbW0xYMAAZGZmllnl1IoVK/Ddd99h6NChsLGxwaBBg5CWlgag5PdBS0sLBw4cwOXLl+Hg4IDJkycXmGL5559/4unTp9i6dStMTEyE7euvvy6T6yQiIvpSiGSyL+tjdkpKCnR1dfEysRZ0tJmTo89Xx65eFR0CUanlSrJw8uJcvH79WqG/xOb/rLfaMhHKGmofP6AIJOmZSOo3R+GxEtGXI/9nk5nfTiiJNSo6HHpH8tzOFR0CEVGlkf9/3sc+OzMrQ0RERERERERE5Y4LnRMRUaUl+/9NUWMRUelERUXB3d290H0ZGRkffMJeampqWYVFREREFYSVUkRERGXk/v37+OGHH1CtWjWoq6vDzs4O586dE/bLZDL4+/vDxMQE6urqcHFxwc2bN+XGePHiBby8vKCjowM9PT0MGDCgwC/nly5dQqtWraCmpgYzMzPMnz+/QCy7du2CjY0N1NTUYGdnh8OHD5fNRRN9QJMmTRAXF1eijYiIiCofVkoREVGllb9IuaLGKo6XL1+iZcuWaNu2LY4cOQJDQ0PcvHkTVatWFfrMnz8fS5cuxaZNm2BpaYmpU6fCzc0N165dEx5N7+XlhYcPHyIiIgI5OTnw8fHB4MGDERISAiBvvr6rqytcXFywcuVKXL58GT/99BP09PQwePBgAEBMTAz69OmDOXPmoEuXLggJCUH37t1x4cIFNGjQQCH3h6go1NXVYWVlVdFhEBER0SeCSSkiIqq8KnD+3rx582BmZoYNGzYIbZaWlv8bTibDkiVLMGXKFHh4eAAANm/eDCMjI4SGhqJ3795ISEhAWFgYzp49iyZNmgAAli1bhk6dOiEoKAimpqbYtm0bsrOzsX79eqiqqqJ+/fqIi4vDokWLhKRUcHAwOnbsiHHjxgEAZsyYgYiICPz2229YuXJlae4KEREREVGJcfoeERFRGdi/fz+aNGmC77//HtWrV4eDgwPWrFkj7L99+zYePXoEFxcXoU1XVxfNmjVDbGwsACA2NhZ6enpCQgoAXFxcoKSkhNOnTwt9WrduDVVVVaGPm5sbbty4gZcvXwp93j5Pfp/88xARERERVQQmpYiIqPL6/+l7itjw/9P3UlJS5LasrKxCT/3vv/9ixYoVsLa2Rnh4OHx9fTFy5Ehs2rQJAPDo0SMAgJGRkdxxRkZGwr5Hjx6hevXqcvurVKkCfX19uT6FjfH2Od7XJ38/EREREVFFYFKKiIioGMzMzKCrqytsc+bMKbSfVCpF48aNMXv2bDg4OGDw4MEYNGgQp8sREREREf0/rilFRESVlkyWtylqLAC4d+8edHR0hHaxWFxofxMTE9SrV0+uzdbWFrt37wYAGBsbAwAeP34MExMToc/jx4/RqFEjoc+TJ0/kxsjNzcWLFy+E442NjfH48WO5PvnvP9Ynfz8RERERUUVgUoqIiCqtsnj6no6OjlxS6n1atmyJGzduyLUlJibC3NwcQN6i58bGxjh+/LiQhEpJScHp06fh6+sLAHBycsKrV69w/vx5ODo6AgBOnDgBqVSKZs2aCX0mT56MnJwcqKioAAAiIiJQt25d4Ul/Tk5OOH78OPz8/IRYIiIi4OTkVMK7QUSlcSXQrUg/R4iIiCo7Tt8jIiIqA6NHj8Y///yD2bNnIykpCSEhIVi9ejWGDRsGABCJRPDz88PMmTOxf/9+XL58GT/++CNMTU3RvXt3AHmVVR07dsSgQYNw5swZREdHY/jw4ejduzdMTU0BAH379oWqqioGDBiAq1evYseOHQgODsaYMWOEWEaNGoWwsDAsXLgQ169fx7Rp03Du3DkMHz683O8LEREREVE+VkoREVHl9dYC5QoZqxi+/vpr7N27FxMnTsT06dNhaWmJJUuWwMvLS+gzfvx4pKWlYfDgwXj16hW++eYbhIWFQU1NTeizbds2DB8+HO3bt4eSkhK+/fZbLF26VNivq6uLo0ePYtiwYXB0dISBgQH8/f0xePBgoU+LFi0QEhKCKVOmYNKkSbC2tkZoaCgaNGhQihtCRERERFQ6IplMUattfB5SUlKgq6uLl4m1oKPNQjH6fHXs6vXxTkSfuFxJFk5enIvXr18rdCpL/s96i3VToaSh9vEDikCanonkATMUHisRfTnyfzbx5wgREVV2Rf0/j5VSRERUaZXFQudERERERKQYTEoREVHlJfv/TVFjERERERGRwnD+GhERERERERERlTtWShERUaUlk4kgU9BC54oah4iIiIiI8jApRURERERUjhoEhENJrFHRYZSZ5LmdKzoEIiL6TDApRURElRvXgiIiIiIi+iQxKUVERJUWp+8REREREX26ipSU2r9/f5EH7NatW4mDISIiIiIiIiKiL0ORklLdu3cv0mAikQgSiaQ08RARESmODIqbvsdpgEREREREClWkpJRUKi3rOIiIiMqA6P83RY1FRERERESKolSagzMzMxUVBxERERERERERfUGKnZSSSCSYMWMGvvrqK2hpaeHff/8FAEydOhXr1q1TeIBEREQlJlPwRkREREREClPspNSsWbOwceNGzJ8/H6qqqkJ7gwYNsHbtWoUGR0RERERERERElVOxk1KbN2/G6tWr4eXlBWVlZaG9YcOGuH79ukKDIyIiKhVWShERERERfbKKnZS6f/8+rKysCrRLpVLk5OQoJCgiIiKFkIkUuxF9Ifr371/kpy9/iEgkQmhoaKnHISIiosqp2EmpevXqISoqqkD7n3/+CQcHB4UERUREREQVJzg4GBs3bqzoMBQiKSkJPj4+qFGjBsRiMSwtLdGnTx+cO3dO6DNr1iy0aNECGhoa0NPTKzDG8+fP0bFjR5iamkIsFsPMzAzDhw9HSkpKOV4JERFR5VOluAf4+/vD29sb9+/fh1QqxZ49e3Djxg1s3rwZBw8eLIsYiYiISkQmy9sUNRZRecrOzpZbv7M86erqVsh531Xae3Du3Dm0b98eDRo0wKpVq2BjY4M3b95g3759+OWXX/DXX38J5/n+++/h5ORU6IN7lJSU4OHhgZkzZ8LQ0BBJSUkYNmwYXrx4gZCQkBLHR0RE9KUrdqWUh4cHDhw4gGPHjkFTUxP+/v5ISEjAgQMH0KFDh7KIkYiIiKjSc3Z2xvDhw+Hn5wcDAwO4ubnhypUrcHd3h5aWFoyMjNCvXz88e/ZM7pgRI0bAz88PVatWhZGREdasWYO0tDT4+PhAW1sbVlZWOHLkiHCMRCLBgAEDYGlpCXV1ddStWxfBwcFysbw7fc/Z2RkjR47E+PHjoa+vD2NjY0ybNk3umJs3b6J169ZQU1NDvXr1EBERUeAa7927h549e0JPTw/6+vrw8PBAcnJygfPOmjULpqamqFu3bonvp0wmQ//+/WFtbY2oqCh07twZtWvXRqNGjRAQEIB9+/YJfQMDAzF69GjY2dkVOlbVqlXh6+uLJk2awNzcHO3bt8fQoUMLnT1ARERERVfspBQAtGrVChEREXjy5AnS09Px999/w9XVVdGxERERlQ4XOqfPzKZNm6Cqqoro6GjMnTsX7dq1g4ODA86dO4ewsDA8fvwYPXv2LHCMgYEBzpw5gxEjRsDX1xfff/89WrRogQsXLsDV1RX9+vVDeno6gLx1QGvUqIFdu3bh2rVr8Pf3x6RJk7Bz586PxqapqYnTp09j/vz5mD59upB4kkql8PT0hKqqKk6fPo2VK1diwoQJcsfn5OTAzc0N2traiIqKQnR0NLS0tNCxY0dkZ2cL/Y4fP44bN24gIiKiVFX4cXFxuHr1Kn755RcoKRX8yFvYNL2ievDgAfbs2YM2bdqUeAwiIiIqwfS9fOfOnUNCQgKAvHWmHB0dFRYUERGRQihygXIudE7lwNraGvPnzwcAzJw5Ew4ODpg9e7awf/369TAzM0NiYiLq1KkDIO8JyFOmTAEATJw4EXPnzoWBgQEGDRoEIG/phRUrVuDSpUto3rw5VFRUEBgYKIxpaWmJ2NhY7Ny5s0DC62329vYICAgQ4vztt99w/PhxdOjQAceOHcP169cRHh4OU1NTAMDs2bPh7u4uHL9jxw5IpVKsXbsWIlHev6cNGzZAT08PkZGRwh84NTU1sXbt2lJPXbx58yYAwMbGplTjvK1Pnz7Yt28fMjIy0LVrV6xdu/aD/bOyspCVlSW85xpURERE8opdKfXff/+hVatWaNq0KUaNGoVRo0bh66+/xjfffIP//vuvLGIkIiIi+iK8/Ue++Ph4nDx5ElpaWsKWn2C5deuW0M/e3l54raysjGrVqslNQzMyMgIAPHnyRGhbvnw5HB0dYWhoCC0tLaxevRp37979YGxvnwcATExMhDETEhJgZmYmJKQAwMnJSa5/fHw8kpKSoK2tLVyPvr4+MjMz5a7Hzs5OIWtpycpgIbjFixfjwoUL2LdvH27duoUxY8Z8sP+cOXOgq6srbGZmZgqPiYiI6HNW7EqpgQMHIicnBwkJCcI8/xs3bsDHxwcDBw5EWFiYwoMkIiIqCZEsb1PUWERlTVNTU3idmpqKrl27Yt68eQX6mZiYCK9VVFTk9olEIrm2/KokqVQKANi+fTvGjh2LhQsXwsnJCdra2liwYAFOnz79wdgKO0/+mEWRmpoKR0dHbNu2rcA+Q0ND4fXb96A08ivJrl+/rrAnRBsbG8PY2Bg2NjbQ19dHq1atMHXqVLmvx9smTpwol7hKSUlhYoqIiOgtxU5K/fXXX4iJiZFbeLJu3bpYtmwZWrVqpdDgiIiIiL5UjRs3xu7du2FhYYEqVUq84kIB0dHRaNGiBYYOHSq0vV2pVBK2tra4d+8eHj58KCRo/vnnH7k+jRs3xo4dO1C9enXo6OiU6nxF0ahRI9SrVw8LFy5Er169Cqwr9erVq1KtK5WfkHt7et67xGIxxGJxic9BRERU2RV7+p6ZmRlycnIKtEskErmSbSIiogrHhc7pMzZs2DC8ePECffr0wdmzZ3Hr1i2Eh4fDx8cHEomkxONaW1vj3LlzCA8PR2JiIqZOnYqzZ8+WKlYXFxfUqVMH3t7eiI+PR1RUFCZPnizXx8vLCwYGBvDw8EBUVBRu376NyMhIjBw5skyWgBCJRNiwYQMSExPRqlUrHD58GP/++y8uXbqEWbNmwcPDQ+h79+5dxMXF4e7du5BIJIiLi0NcXBxSU1MBAIcPH8aGDRtw5coVJCcn49ChQ/j555/RsmVLWFhYKDx2IiKiL0Wxk1ILFizAiBEjcO7cOaHt3LlzGDVqFIKCghQaHBERUankL3SuqI2oHJmamiI6OhoSiQSurq6ws7ODn58f9PT0Cn2aXFENGTIEnp6e6NWrF5o1a4bnz5/LVU2VhJKSEvbu3YuMjAw0bdoUAwcOxKxZs+T6aGho4NSpU6hZsyY8PT1ha2uLAQMGIDMzs8wqp5o2bYpz587BysoKgwYNgq2tLbp164arV69iyZIlQj9/f384ODggICAAqampcHBwEJ56CADq6upYs2YNvvnmG9ja2mL06NHo1q1bqZ4OSERERIBIVoRVIKtWrSqsRwAAaWlpyM3NFUrJ819ramrixYsXZRetAqSkpEBXVxcvE2tBR7vkH+iIKlrHrl4VHQJRqeVKsnDy4ly8fv1aob+U5v+sN1s8A0rqagoZU5qRiXujpyo8ViL6cgg/m/x2QkmsUdHhlJnkuZ0rOgQiIqpg+f/nfeyzc5EWKHj7L0lERESfDUVOu+P0PSIiIiIihSpSUsrb27us4yAiIiIikhMVFQV3d/dC92VkZEBdXf29x+avB0VERESfrlI9yiUzMxPZ2dlybZzSQEREnwxWShF91po0aYK4uLhC930sKUVERESfvmInpdLS0jBhwgTs3LkTz58/L7C/NE+DISIiUigmpYg+a+rq6rCysqroMIiIiKiMFHul7/Hjx+PEiRNYsWIFxGIx1q5di8DAQJiammLz5s1lESMREREREREREVUyxa6UOnDgADZv3gxnZ2f4+PigVatWsLKygrm5ObZt2wYvLz4RjIiIPhEyUd6mqLGIiIiIiEhhil0p9eLFC9SqVQtA3vpRL168AAB88803OHXqlGKjIyIiIiIiIiKiSqnYSalatWrh9u3bAAAbGxvs3LkTQF4FlZ6enkKDIyIiKg2RTLEbEREREREpTrGTUj4+PoiPjwcA/Prrr1i+fDnU1NQwevRojBs3TuEBEhERlZhMwRsRERERESlMsdeUGj16tPDaxcUF169fx/nz52FlZQV7e3uFBkdEREREVNlcCXSDjo5ORYdBRERU4YqdlHqXubk5zM3NFRELERERERERERF9IYqUlFq6dGmRBxw5cmSJgyEiIiIiIiIioi9DkZJSixcvLtJgIpHos0lK9ahjhyoilYoOg6jElNRuVXQIRKUmkmWX7fhQ3ALlIsUMQ0RERERE/69ISan8p+0RERF9VmSivE1RYxERERERkcIU++l7REREREREREREpVXqhc6JiIg+WbL/3xQ1FhERERERKQwrpYiIiIiIiIiIqNyxUoqIiCovVkoR0SeoQUA4lMQaFR0GUYVKntu5okMgok8Ak1JERFRpiWQKfPoek1JERERERApVoul7UVFR+OGHH+Dk5IT79+8DALZs2YK///5bocEREREREREREVHlVOyk1O7du+Hm5gZ1dXVcvHgRWVlZAIDXr19j9uzZCg+QiIioxGQK3oiIiIiISGGKnZSaOXMmVq5ciTVr1kBFRUVob9myJS5cuKDQ4IiIiIiIiIiIqHIq9ppSN27cQOvWrQu06+rq4tWrV4qIiYiISDG40DkRERER0Ser2JVSxsbGSEpKKtD+999/o1atWgoJioiISBHyFzpX1EZERERERIpT7KTUoEGDMGrUKJw+fRoikQgPHjzAtm3bMHbsWPj6+pZFjEREREREREREVMkUe/rer7/+CqlUivbt2yM9PR2tW7eGWCzG2LFjMWLEiLKIkYiIqGRkorxNUWMREREREZHCFDspJRKJMHnyZIwbNw5JSUlITU1FvXr1oKWlVRbxERERERERERFRJVTspFQ+VVVV1KtXT5GxEBERKRYXOiciIiIi+mQVOynVtm1biETvn8Jw4sSJUgVERESkKIpcoJwLndPnqH///nj16hVCQ0NLNY5IJMLevXvRvXt3hcRVHiIjI9G2bVu8fPkSenp6hfbZuHEj/Pz8+ARpIiKiClLspFSjRo3k3ufk5CAuLg5XrlyBt7e3ouIiIiIiolIKDg6GTMaMammdOnUKCxYswPnz5/Hw4cPPLkFHRET0qSp2Umrx4sWFtk+bNg2pqamlDoiIiEhhOH2PPgHZ2dlQVVWtkHPr6upWyHnfVZH3oDTy405LS0PDhg3x008/wdPTs6LDIiIiqjSUFDXQDz/8gPXr1ytqOCIiIqLPkrOzM4YPHw4/Pz8YGBjAzc0NV65cgbu7O7S0tGBkZIR+/frh2bNncseMGDECfn5+qFq1KoyMjLBmzRqkpaXBx8cH2trasLKywpEjR4RjJBIJBgwYAEtLS6irq6Nu3boIDg6Wi6V///5yFT3Ozs4YOXIkxo8fD319fRgbG2PatGlyx9y8eROtW7eGmpoa6tWrh4iIiALXeO/ePfTs2RN6enrQ19eHh4cHkpOTC5x31qxZMDU1Rd26dUt1T7ds2YImTZpAW1sbxsbG6Nu3L548eSLX5/Dhw6hTpw7U1dXRtm1buXjybdy4ETVr1oSGhgZ69OiB58+fy+2fNm0aGjVqhLVr18LS0hJqamoAAHd3d8ycORM9evQo1XUQERGRPIUlpWJjY4X/uImIiD4Jsv+tK1XajZVSVBybNm2CqqoqoqOjMXfuXLRr1w4ODg44d+4cwsLC8PjxY/Ts2bPAMQYGBjhz5gxGjBgBX19ffP/992jRogUuXLgAV1dX9OvXD+np6QAAqVSKGjVqYNeuXbh27Rr8/f0xadIk7Ny586OxaWpq4vTp05g/fz6mT58uJJ6kUik8PT2hqqqK06dPY+XKlZgwYYLc8Tk5OXBzc4O2tjaioqIQHR0NLS0tdOzYEdnZ2UK/48eP48aNG4iIiMDBgwdLdT9zcnIwY8YMxMfHIzQ0FMnJyejfv7+w/969e/D09ETXrl0RFxeHgQMH4tdff5Ub4/Tp0xgwYACGDx+OuLg4tG3bFjNnzixwrqSkJOzevRt79uxBXFxcqeLOyspCSkqK3EZERET/U+zpe++WLMtkMjx8+BDnzp3D1KlTFRYYERFRqXH6HlUQa2trzJ8/HwAwc+ZMODg4YPbs2cL+9evXw8zMDImJiahTpw4AoGHDhpgyZQoAYOLEiZg7dy4MDAwwaNAgAIC/vz9WrFiBS5cuoXnz5lBRUUFgYKAwpqWlJWJjY7Fz584CCa+32dvbIyAgQIjzt99+w/Hjx9GhQwccO3YM169fR3h4OExNTQEAs2fPhru7u3D8jh07IJVKsXbtWuHhNxs2bICenh4iIyPh6uoKANDU1MTatWsVMm3vp59+El7XqlULS5cuxddff43U1FRoaWlhxYoVqF27NhYuXAgAqFu3Li5fvox58+YJxwUHB6Njx44YP348AKBOnTqIiYlBWFiY3Lmys7OxefNmGBoaljruOXPmyH2NiIiISF6xK6V0dXXlNn19fTg7O+Pw4cPCBxwiIiKiL5mjo6PwOj4+HidPnoSWlpaw2djYAABu3bol9LO3txdeKysro1q1arCzsxPajIyMAEBu2try5cvh6OgIQ0NDaGlpYfXq1bh79+4HY3v7PABgYmIijJmQkAAzMzMhIQUATk5Ocv3j4+ORlJQEbW1t4Xr09fWRmZkpdz12dnYKW0fq/Pnz6Nq1K2rWrAltbW20adMGAIRrTUhIQLNmzeSOeTfuovQBAHNzc4UkpIC85OLr16+F7d69ewoZl4iIqLIoVqWURCKBj48P7OzsULVq1bKKiYiISDFYKUUVRFNTU3idmpqKrl27ylXt5DMxMRFeq6ioyO0TiURybflVSVKpFACwfft2jB07FgsXLoSTkxO0tbWxYMECnD59+oOxFXae/DGLIjU1FY6Ojti2bVuBfW8nc96+B6WRlpYGNzc3uLm5Ydu2bTA0NMTdu3fh5uYmN11QURQVNwCIxWKIxWKFjUdERFTZFCsppaysDFdXVyQkJDApRUREnzxhPSgFjUVUEo0bN8bu3bthYWGBKlWKvXLCe0VHR6NFixYYOnSo0PZ2pVJJ2Nra4t69e3j48KGQMPvnn3/k+jRu3Bg7duxA9erVoaOjU6rzFcX169fx/PlzzJ07F2ZmZgCAc+fOFYh7//79cm3vxm1ra1sgYfduHyIiIipfxZ6+16BBA/z7779lEQsRERFRpTNs2DC8ePECffr0wdmzZ3Hr1i2Eh4fDx8cHEomkxONaW1vj3LlzCA8PR2JiIqZOnYqzZ8+WKlYXFxfUqVMH3t7eiI+PR1RUFCZPnizXx8vLCwYGBvDw8EBUVBRu376NyMhIjBw5Ev/991+pzl+YmjVrQlVVFcuWLcO///6L/fv3Y8aMGXJ9fv75Z9y8eRPjxo3DjRs3EBISgo0bN8r1GTlyJMLCwhAUFISbN2/it99+K7Ce1PukpqYiLi5OWPj89u3biIuL++hUSSIiIvqwYielZs6cibFjx+LgwYN4+PAhnyhCRERE9AGmpqaIjo6GRCKBq6sr7Ozs4OfnBz09PSgplfxByEOGDIGnpyd69eqFZs2a4fnz53JVUyWhpKSEvXv3IiMjA02bNsXAgQMxa9YsuT4aGho4deoUatasCU9PT9ja2mLAgAHIzMwsk8opQ0NDbNy4Ebt27UK9evUwd+5cBAUFyfWpWbMmdu/ejdDQUDRs2BArV66UW1geAJo3b441a9YgODgYDRs2xNGjR4WF5T/m3LlzcHBwgIODAwBgzJgxcHBwgL+/v2IukoiI6AslkslkRZqQMH36dPzyyy/Q1tb+38H/v7YBkPcUPpFIVKq/+JWHlJQU6OrqwhkeqCJS+fgBRJ8oJTW1ig6BqNRyZdk4kbkTr1+/Vugvs/k/62tPmg1lBf1bkWRm4tbsSQqPlYi+HPk/m8z8dkJJrFHR4RBVqOS5nSs6BCIqQ/n/533ss3ORFzYIDAzEzz//jJMnTyokQCIiojLHhc6JiIiIiD5ZRU5K5RdU5T+Cl4iI6FPHhc6JPg1RUVFwd3cvdF9GRgbU1dXfe2xqampZhUVEREQVrFiPgHl7uh4RERERUVE0adJEWCT8XR9LShEREVHlVaykVJ06dT6amHrx4kWpAiIiIlIoVjgRVTh1dXVYWVlVdBhERET0iSlWUiowMBC6urplFQsREREREREREX0hipWU6t27N6pXr15WsRARESkWFzonIiIiIvpkFTkpxfWkiIjoc8OFzomIiIiIPl1KRe2Y//Q9IiIiIiIiIiKi0ipypZRUKi3LOIiIiBSP0/eIiIiIiD5ZxVpTioiIiIiISudKoBt0dHQqOgwiIqIKV+Tpe0RERJ+b/DWlFLWV1Ny5cyESieDn5ye0ZWZmYtiwYahWrRq0tLTw7bff4vHjx3LH3b17F507d4aGhgaqV6+OcePGITc3V65PZGQkGjduDLFYDCsrK2zcuLHA+ZcvXw4LCwuoqamhWbNmOHPmTMkvhoiIiIhIQZiUIiKiykum4K0Ezp49i1WrVsHe3l6uffTo0Thw4AB27dqFv/76Cw8ePICnp6ewXyKRoHPnzsjOzkZMTAw2bdqEjRs3wt/fX+hz+/ZtdO7cGW3btkVcXBz8/PwwcOBAhIeHC3127NiBMWPGICAgABcuXEDDhg3h5uaGJ0+elOyCiIiIiIgUhEkpIiKiMpKamgovLy+sWbMGVatWFdpfv36NdevWYdGiRWjXrh0cHR2xYcMGxMTE4J9//gEAHD16FNeuXcPWrVvRqFEjuLu7Y8aMGVi+fDmys7MBACtXroSlpSUWLlwIW1tbDB8+HN999x0WL14snGvRokUYNGgQfHx8UK9ePaxcuRIaGhpYv359+d4MIiIiIqJ3MClFRESVVwVXSg0bNgydO3eGi4uLXPv58+eRk5Mj125jY4OaNWsiNjYWABAbGws7OzsYGRkJfdzc3JCSkoKrV68Kfd4d283NTRgjOzsb58+fl+ujpKQEFxcXoQ8RERERUUXhQudERETFkJKSIvdeLBZDLBYX6Ld9+3ZcuHABZ8+eLbDv0aNHUFVVhZ6enly7kZERHj16JPR5OyGVvz9/34f6pKSkICMjAy9fvoREIim0z/Xr14twtUREREREZYeVUkREVGmVxULnZmZm0NXV/b/27j0uqjr/H/hrQGa4zYDIPVEoBHFFBVTE3TU0Alnzp4ullV9DQ0tFCMk0SvGSitpaauIlWS+7qwlu4W7eCDGUCFG08ZKCSrjgBngLEOQmc35/uJycQBEYGBhez8fjPJw553M+5/05ZxgObz+fzxGXmJiYBsctKCjAO++8g927d8PQ0LCdW01ERERE1DmwpxQREemuVkxQ3mhdeJhwevRR7o31kjpz5gxu3rwJT09PcV1dXR1OnDiBjRs3IikpCTU1NSgpKVHrLVVcXAxbW1sAgK2tbYOn5NU/ne/RMr99Yl9xcTEUCgWMjIygr68PfX39RsvU10FEREREpC1MShERETWDQqFQS0o15oUXXsCFCxfU1k2bNg19+/bFggUL4ODgAAMDA6SkpGDChAkAgJycHOTn58PHxwcA4OPjgxUrVuDmzZuwtrYGACQnJ0OhUKBfv35imUOHDqkdJzk5WaxDKpXCy8sLKSkpGD9+PABApVIhJSUFc+bMad2JIKIW6784CXoyY22HQR3U9VVjtB0CEVG7YVKKiIh0Vxv0lHoacrkc/fv3V1tnYmKCHj16iOtDQkIQGRkJCwsLKBQKhIWFwcfHB8OGDQMA+Pv7o1+/fpgyZQrWrFmDoqIiLFy4EKGhoWLvrJkzZ2Ljxo2YP38+3nzzTRw7dgwJCQk4ePCgeNzIyEgEBwdj8ODBGDp0KNatW4eKigpMmzatlSeEiIiIiKh1mJQiIiLSgk8//RR6enqYMGECqqurERAQgE2bNonb9fX1ceDAAcyaNQs+Pj4wMTFBcHAwli1bJpZxcnLCwYMHMXfuXKxfvx49e/ZEXFwcAgICxDKTJk3CrVu3EB0djaKiIgwaNAhHjhxpMPk5EREREVF7kwiCoKn/Q+4UysrKYGZmBl+MQzeJgbbDIWoxPU6eTDrggVCDY1UJKC0tbXJIXHPUf9f3DV8JfZlmflbqqquQveEDjcdKRF1H/XeTQ0QCh+/RY3H4HhHpgvrfeU3dO7OnFBER6S4tDd8jIiIiIqKm6Wk7ACIiIiIiIiIi6nrYU4qIiHSWRHi4aKouIiIiIiLSHPaUIiIiIiIiIiKidseeUkREpLs4pxQRERERUYfFpBQREekuJqWIiIiIiDosDt8jIiIiItHUqVMxfvz4VtcjkUiwf//+VtdDREREuotJKSIi0lkSDS9EXcH69euxc+dObYfRar6+vpBIJJBIJJDJZHjmmWcwduxYfPXVVw3KrlixAsOHD4exsTHMzc0bra++rkeXvXv3tnEriIiIdBuTUkREREQdTE1NjdaObWZm9tjETHvSxDmYMWMGCgsLkZubiy+//BL9+vXDq6++irfeeqvBsV555RXMmjXrifXt2LEDhYWF4qKJHmVERERdGZNSRESkuwQNL0RtxNfXF3PmzEFERAQsLS0REBCAixcvIjAwEKamprCxscGUKVNw+/ZttX3CwsIQERGB7t27w8bGBtu2bUNFRQWmTZsGuVwOZ2dnHD58WNynrq4OISEhcHJygpGREVxdXbF+/Xq1WH47fM/X1xfh4eGYP38+LCwsYGtriyVLlqjtc/XqVYwYMQKGhobo168fkpOTG7SxoKAAEydOhLm5OSwsLDBu3Dhcv369wXFXrFgBe3t7uLq6tu6kAjA2NoatrS169uyJYcOGYfXq1di6dSu2bduGo0ePiuWWLl2KuXPnwt3d/Yn1mZubw9bWVlwMDQ1bHSMREVFXxqQUERHpLImg2YWoLe3atQtSqRTp6elYtWoVRo0aBQ8PD2RlZeHIkSMoLi7GxIkTG+xjaWmJU6dOISwsDLNmzcIrr7yC4cOH4+zZs/D398eUKVNw//59AIBKpULPnj2xb98+XLp0CdHR0fjggw+QkJDQZGwmJibIzMzEmjVrsGzZMjHxpFKpEBQUBKlUiszMTGzZsgULFixQ27+2thYBAQGQy+VIS0tDeno6TE1NMXr0aLUeUSkpKcjJyUFycjIOHDigidPaQHBwMLp3797oML6mhIaGwtLSEkOHDsX27dshCE/+YqiurkZZWZnaQkRERL/i0/eIiIiIOoA+ffpgzZo1AIDly5fDw8MDK1euFLdv374dDg4OuHLlClxcXAAAAwcOxMKFCwEAUVFRWLVqFSwtLTFjxgwAQHR0NDZv3ozz589j2LBhMDAwwNKlS8U6nZyckJGRgYSEhAYJr0cNGDAAixcvFuPcuHEjUlJS8OKLL+Lo0aPIzs5GUlIS7O3tAQArV65EYGCguH98fDxUKhXi4uIgkTycoW3Hjh0wNzdHamoq/P39AQAmJiaIi4uDVCpt3cl8Aj09Pbi4uKj10noay5Ytw6hRo2BsbIxvvvkGs2fPRnl5OcLDwx+7T0xMjNr5JiIiInVMShERke7S5LA79pSiNubl5SW+PnfuHL799luYmpo2KJebmysmpQYMGCCu19fXR48ePdSGoNnY2AAAbt68Ka6LjY3F9u3bkZ+fj8rKStTU1GDQoEFPjO3R4wCAnZ2dWOfly5fh4OAgJqQAwMfHR638uXPncO3aNcjlcrX1VVVVyM3NFd+7u7u3aUKqniAIYnLsaS1atEh87eHhgYqKCnz88cdPTEpFRUUhMjJSfF9WVgYHB4fmB0xERKSjmJQiIiIi6gBMTEzE1+Xl5Rg7dixWr17doJydnZ342sDAQG2bRCJRW1efeFGpVACAvXv3Yt68eVi7di18fHwgl8vx8ccfIzMz84mxNXac+jqfRnl5Oby8vLB79+4G26ysrMTXj56DtlJXV4erV69iyJAhrarH29sbH330EaqrqyGTyRotI5PJHruNiIiImJQiIiJdxx5O1Al5enriyy+/hKOjI7p109ztWnp6OoYPH47Zs2eL6x7tqdQSbm5uKCgoQGFhoZgwO3nypFoZT09PxMfHw9raGgqFolXHa61du3bhl19+wYQJE1pVj1KpRPfu3Zl0IiIiagVOdE5ERDqLE51TZxUaGoq7d+/itddew+nTp5Gbm4ukpCRMmzYNdXV1La63T58+yMrKQlJSEq5cuYJFixbh9OnTrYrVz88PLi4uCA4Oxrlz55CWloYPP/xQrczkyZNhaWmJcePGIS0tDXl5eUhNTUV4eDhu3LjRquM/yf3791FUVIQbN27g5MmTWLBgAWbOnIlZs2Zh5MiRYrn8/HwolUrk5+ejrq4OSqUSSqUS5eXlAICvv/4acXFxuHjxIq5du4bNmzdj5cqVCAsLa7PYiYiIugImpYiIiIg6GHt7e6Snp6Ourg7+/v5wd3dHREQEzM3NoafX8tu3t99+G0FBQZg0aRK8vb1x584dtV5TLaGnp4fExERUVlZi6NChmD59OlasWKFWxtjYGCdOnECvXr0QFBQENzc3hISEoKqqqk17Tm3btg12dnZ47rnnEBQUhEuXLiE+Ph6bNm1SKxcdHQ0PDw8sXrwY5eXl8PDwEJ98CDwcvhgbGwsfHx8MGjQIW7duxSeffCJO/k5EREQtIxGaepatjikrK4OZmRl8MQ7dJAZN70DUQekZGmo7BKJWeyDU4FhVAkpLSzX6h2n9d33/GSuhL9XMz0pdTRUubvtA47ESUddR/93kEJEAPZmxtsOhDur6qjHaDoGIqNXqf+c1de/MnlJERERERERERNTuONE5ERHpLE3OBcU5pYjaV1paGgIDAxvdVllZCSMjo8fuWz8XFBEREXVsTEoREZHuEqC5p+8xKUXUrgYPHgylUtnotqaSUkRERNQ5MClFRERERB2OkZERnJ2dtR0GERERtSEmpYiISGdx+B4RERERUcfFic6JiIiIiIiIiKjdsacUERHpLs4pRURERETUYTEpRUREuotJKSIiIiKiDovD94iIiIiIiIiIqN2xpxQREeksTnRORB3RxaUBUCgU2g6DiIhI65iUIiIi3cXhe0REREREHRaH7xERERERERERUbtjTykiItJZEkGARNBMFydN1UNERERERA+xpxQREREREREREbU79pQiIiLdxTmliIiIiIg6LCaliIhIZ/Hpe0REREREHReH7xERERERERERUbtjTyl6Knp6Av7v3SK8MKEE3a1qcafYAMkJFtizzhqA5H+lBLzxXjFGv34Hpoo6XMoywYb3e+LnPFmD+gykKqw/eBXP/a4Ks150wU8/GrVre6hrGDO5GGMmF8PmmWoAwH+uGmPPZ88g67j5b0oKWLY9B0N8S7Hs7T7ISLYAAMjNazH/01w49b0PhfkDlNwxQMbR7tj1l564X/7r1+fIcbfx8luFsHeswv17+sg6bo64GAfcKzFop5bSY3H4HhF1QP0XJ0FPZqztMIiIiETXV43RynHZU4qeysTQm3gp+A5iP3wGM57vi7+usMMrs29iXMjtR8rcwrg3b+Gz93vinZf6oOq+Hlbu+QkGMlWD+kIWFuJOEf9gp7Z1u1CKHWt6IWycO8LH98e5DAWit15Brz731cqNf7Oo0f0FlQQnj3bH0rdcMP2Fgfhk/rPw+H0p5iy/Lpbp53UP7/4lF0kJVpgZ4I6Vc/rAZUA53onJa8umERERERERdXpaTUqdOHECY8eOhb29PSQSCfbv39/kPqmpqfD09IRMJoOzszN27tzZ5nES0G9wBTKSzHAqRYHiG1J8d9AcZ4/L4Tqo/o97AeOn38IX622QkWSGvMtGWBPeCz1sajF8dKlaXYNHlsHr+XvYtsy+/RtCXUrmse44nWqOn68b4r95Rti11gFV9/XQ16NcLPOsWwUmhBTi0/nPNti/vKwbDu62wdULprj5swzK781w4B826D/4nljGzaMcN2/I8O9dtii+YYgfs+Q4/IU1XAeUN6iP2l/9nFKaWoiIiIiISHO0mpSqqKjAwIEDERsb+1Tl8/LyMGbMGIwcORJKpRIRERGYPn06kpKS2jhSupRlgkF/uIdnnn04DOrZfpX43dAKnD6mAADY9qpBD5sHOJsmF/e5f08f2T8Yw83r114p5pa1iPj4BtaE9UJ1JTvqUfvR0xPw/Et3YGikQvZZUwCAzLAOC9ZdQ+xiR/xyW9pkHRbWNfh9wF1cOPXr5/zyD6awtKvBEN8SAALMLWvxh8C7OJ1q3jYNoeYRNLwQEREREZHGaHVOqcDAQAQGBj51+S1btsDJyQlr164FALi5ueG7777Dp59+ioCAgLYKkwDEb7SGsbwOcSeyoaoD9PSBnats8W1idwCAhfUDAEDJLfWPVMmtbrCwrv3fOwHz1hXg4N974Op5Y9j0rGnPJlAX5eh6H5/880dIZSpU3tfHR7NckH/t4Tweby3Mx6Wzcpw8avHEOhasv4Zhfr/A0EiFk0fNse79X3tVXTojx5q5z+H9DVchlQnoZiDg5FFzxC52bMtmERERERERdXqdqqtKRkYG/Pz81NYFBAQgIyPjsftUV1ejrKxMbaHmG/H/SjAqqASrQnshNMAFf3nHAS/PvAW/V+4+dR3jQm7DyLQO8Z9Zt2GkROpu/GSI0JfcERHUHwd3W+Pdj3PRy/k+vF/4BQOHl2LrR72brOPzj3ohbGx/LJnhArte1Xhr4X/Ebb2c72Nm9H+w57NnEDauPz4MdoVNz2qEPTLvFGkPh+8REREREXVcnerpe0VFRbCxsVFbZ2Njg7KyMlRWVsLIqOET3GJiYrB06dL2ClFnzVhUiPiN1jj+r4c9o65nG8G6Zy1eDbuJo/sscPfmw4+SudUD3L356wTm5lYPkPu/J+sN+n053Lzu48D182p1bzx8Bce+6o6/RPRqp9ZQV/KgVg+F/zEEAFy7aAKXARUYN7UYNdV6sOtVjX8qs9TKf7jpKn48LceC1/uJ6365LcUvt4EbPxmhvLQb/pJwCXs+ewa/3JJi4qyfcemMHF9uezhH2vVsY8RW6uMvCZewa21P/HKr6WGBREREREREXVGnSkq1RFRUFCIjI8X3ZWVlcHBw0GJEnZPMUAXhNw/RU9UBkv91HSjKl+JOcTd4/OEefvpfEsrYtA59Pe7jwN96AAA2LXoGO1fbivv3sH2AmC9+wsqZvZH9Ax+LTO1DIgEMpCr8Y90zOBJvpbZty5EL+Hx5b2SmmD9h/4efeQPpw39lRirUPZColamr+/VYpGWanAuKPaWIiIiIiDSqUyWlbG1tUVxcrLauuLgYCoWi0V5SACCTySCTydojPJ12MlmBV8Nv4uZ/pfhPjiGe61+JoLdv4Zu99XPxSLA/zgqvvXMT/82ToShfiuD5RbhTbIDvj5gBAG79V73HSFXFwzmlfv6PDLcL2ZuENG/qe/nISjXHzZ9lMDatg+//u40Bw8qwcGrf//V+avi5u/WzFMU3HvasGuJbAnPLWlw5b4LKCn30drmP6e/n48csU9z878PvlcyU7nhnZR7GTC7GmRNmsLCuxduL/oNspQnu3uTnuiPgsDsiIiIioo6pUyWlfHx8cOjQIbV1ycnJ8PHx0VJEXcemhc8geH4R5sTcgHmPB7hTbIBDf++B3Z/+OpwyIdYKhsYqvLPmBkwVdfjxtAk+nPwsaqs71dRlpEPMezzAvLW5sLCqRcU9feTlGGPh1L744Tuzp9q/ukqC0ZNu4q2FlTCQqnCrUIbvk7ojYbO9WObol1YwNqnD2CnFmP5BPirK9HEuQ4HtqzkclYiIiIiI6EkkgiBo7f+Qy8vLce3aNQCAh4cHPvnkE4wcORIWFhbo1asXoqKi8N///hd/+9vfAAB5eXno378/QkND8eabb+LYsWMIDw/HwYMHn/rpe2VlZTAzM4MvxqGbxKDpHYg6KD1DQ22HQNRqD4QaHKtKQGlpKRQKhcbqrf+u93plOboZaOZn5UFtFc7sW6jxWIm0ZerUqSgpKcH+/ftbVY9EIkFiYiLGjx+vkbg0wdHREREREYiIiADQcWKs/25yiEiAnoxTFxARUcdxfdUYjdZX/zuvqXtnrXZhycrKgoeHBzw8PAAAkZGR8PDwQHR0NACgsLAQ+fn5YnknJyccPHgQycnJGDhwINauXYu4uLinTkgRERER0UPr16/Hzp07tR1GuygsLERgYOBTlZVIJA0SdYWFhXj99dfh4uICPT09MdlFREREraPV4Xu+vr54Uketxm6UfH198cMPP7RhVEREpCskgubmlOLcVNQWampqIJVqZ/45M7OnG8rc1trjHNja2jZd6Amqq6thZWWFhQsX4tNPP9VQVERERMTJfoiISHcJGl6IWsnX1xdz5sxBREQELC0tERAQgIsXLyIwMBCmpqawsbHBlClTcPv2bbV9wsLCEBERge7du8PGxgbbtm1DRUUFpk2bBrlcDmdnZxw+fFjcp66uDiEhIXBycoKRkRFcXV2xfv16tVimTp2qNpzN19cX4eHhmD9/PiwsLGBra4slS5ao7XP16lWMGDEChoaG6NevH5KTkxu0saCgABMnToS5uTksLCwwbtw4XL9+vcFxV6xYAXt7e7i6urbqnN68eRNjx46FkZERnJycsHv37gZlHu39VFNTgzlz5sDOzg6Ghobo3bs3YmJiADwc9gcAf/7znyGRSMT3jo6OWL9+Pd54440Ok8wjIiLSBUxKEREREbWjXbt2QSqVIj09HatWrcKoUaPg4eGBrKwsHDlyBMXFxZg4cWKDfSwtLXHq1CmEhYVh1qxZeOWVVzB8+HCcPXsW/v7+mDJlCu7fvw8AUKlU6NmzJ/bt24dLly4hOjoaH3zwARISEpqMzcTEBJmZmVizZg2WLVsmJp5UKhWCgoIglUqRmZmJLVu2YMGCBWr719bWIiAgAHK5HGlpaUhPT4epqSlGjx6NmpoasVxKSgpycnKQnJyMAwcOtOp8Tp06FQUFBfj222/xz3/+E5s2bcLNmzcfW37Dhg3497//jYSEBOTk5GD37t1i8un06dMAgB07dqCwsFB8T0RERG2jUz19j4iIqDkkqoeLpuoi0oQ+ffpgzZo1AIDly5fDw8MDK1euFLdv374dDg4OuHLlClxcXAAAAwcOxMKFCwEAUVFRWLVqFSwtLTFjxgwAQHR0NDZv3ozz589j2LBhMDAwwNKlS8U6nZyckJGRgYSEhAYJr0cNGDAAixcvFuPcuHEjUlJS8OKLL+Lo0aPIzs5GUlIS7O0fPoV05cqVanM1xcfHQ6VSIS4uDhKJBMDDBI+5uTlSU1Ph7+8PADAxMUFcXFyrh+1duXIFhw8fxqlTpzBkyBAAwF//+le4ubk9dp/8/Hz06dMHf/jDHyCRSNC7d29xm5WVFQDA3Ny81UP+gIfD/qqrq8X3ZWVlra6TiIhIl7CnFBEREVE78vLyEl+fO3cO3377LUxNTcWlb9++AIDc3Fyx3IABA8TX+vr66NGjB9zd3cV1NjY2AKDWQyg2NhZeXl6wsrKCqakpPv/8c7UHyDTm0eMAgJ2dnVjn5cuX4eDgICakAMDHx0et/Llz53Dt2jXI5XKxPRYWFqiqqlJrj7u7u0bmkbp8+TK6deumdk779u0Lc3Pzx+4zdepUKJVKuLq6Ijw8HN98802r43icmJgYmJmZiYuDg0ObHYuIiKgzYk8pIiLSXZqcC4pzSpGGmJiYiK/Ly8sxduxYrF69ukE5Ozs78bWBgYHaNolEorauvleSSvWwS9/evXsxb948rF27Fj4+PpDL5fj444+RmZn5xNgaO059nU+jvLwcXl5ejc7rVN8LCVA/B+3N09MTeXl5OHz4MI4ePYqJEyfCz88P//znPzV+rKioKERGRorvy8rKmJgiIiJ6BJNSRESks/j0PeroPD098eWXX8LR0RHdumnutiw9PR3Dhw/H7NmzxXWP9lRqCTc3NxQUFKCwsFBMmJ08eVKtjKenJ+Lj42FtbQ2FQtGq4z2Nvn374sGDBzhz5ow4fC8nJwclJSVP3E+hUGDSpEmYNGkSXn75ZYwePRp3796FhYUFDAwMUFdXp5H4ZDIZZDKZRuoiIiLSRRy+R0RERKQloaGhuHv3Ll577TWcPn0aubm5SEpKwrRp01qVGOnTpw+ysrKQlJSEK1euYNGiRa2etNvPzw8uLi4IDg7GuXPnkJaWhg8//FCtzOTJk2FpaYlx48YhLS0NeXl5SE1NRXh4OG7cuNGq4zfG1dUVo0ePxttvv43MzEycOXMG06dPh5GR0WP3+eSTT/DFF18gOzsbV65cwb59+2BraysO+XN0dERKSgqKiorwyy+/iPsplUoolUqUl5fj1q1bUCqVuHTpksbbRERE1JUwKUVERLpLEDS7EGmYvb090tPTUVdXB39/f7i7uyMiIgLm5ubQ02v5bdrbb7+NoKAgTJo0Cd7e3rhz545ar6mW0NPTQ2JiIiorKzF06FBMnz4dK1asUCtjbGyMEydOoFevXggKCoKbmxtCQkJQVVXVZj2nduzYAXt7ezz//PMICgrCW2+9BWtr68eWl8vlWLNmDQYPHowhQ4bg+vXrOHTokHi+165di+TkZDg4OMDDw0Pcz8PDAx4eHjhz5gz27NkDDw8P/OlPf2qTNhEREXUVEkHoWnfZZWVlMDMzgy/GoZvEoOkdiDooPUNDbYdA1GoPhBocq0pAaWmpRv9grf+uH/r/PkI3A838rDyorcKpfy/SeKxE1HXUfzc5RCRAT2as7XCIiIhE11eN0Wh99b/zmrp35pxSRESkszinFBERERFRx8WkFBER6S4+fY+ow0tLS0NgYGCj2yorK584P1R5eXlbhUVERETtgEkpIiIiItKawYMHQ6lUNrqtqaQUERERdW5MShERkc7i8D2ijs/IyAjOzs7aDoOIiIi0gE/fIyIiIiIiIiKidseeUkREpLsE4eGiqbqIiIiIiEhjmJQiIiKdxeF7REREREQdF4fvERERERERERFRu2NPKSIi0l3C/xZN1UVERERERBrDpBQRERERUTu6uDQACoVC22EQERFpHZNSRESkszinFBERERFRx8WkFBER6S6V8HDRVF1ERERERKQxnOiciIiIiIiIiIjaHXtKERGR7uJE50REREREHRZ7ShERERERERERUbtjTykiItJZEmhwonPNVENERERERP/DpBQREekuQXi4aKouIiIiIiLSGCaliIiIiIjaUf/FSdCTGWs7DGpH11eN0XYIREQdEpNSRESksySCBofvsaMUEREREZFGcaJzIiKiNhATE4MhQ4ZALpfD2toa48ePR05OjlqZqqoqhIaGokePHjA1NcWECRNQXFysViY/Px9jxoyBsbExrK2t8d577+HBgwdqZVJTU+Hp6QmZTAZnZ2fs3LmzQTyxsbFwdHSEoaEhvL29cerUKY23mYiIiIioOZiUIiIi3SVoeGmG48ePIzQ0FCdPnkRycjJqa2vh7++PiooKsczcuXPx9ddfY9++fTh+/Dh+/vlnBAUFidvr6uowZswY1NTU4Pvvv8euXbuwc+dOREdHi2Xy8vIwZswYjBw5EkqlEhEREZg+fTqSkpLEMvHx8YiMjMTixYtx9uxZDBw4EAEBAbh582bzGkVEREREpEESQehaM7eWlZXBzMwMvhiHbhIDbYdD1GJ6hobaDoGo1R4INThWlYDS0lIoFAqN1Vv/Xf9H38Xo1k0zPysPHlQhLXVpi2O9desWrK2tcfz4cYwYMQKlpaWwsrLCnj178PLLLwMAsrOz4ebmhoyMDAwbNgyHDx/GSy+9hJ9//hk2NjYAgC1btmDBggW4desWpFIpFixYgIMHD+LixYvisV599VWUlJTgyJEjAABvb28MGTIEGzduBACoVCo4ODggLCwM77//fmtPDRE9pfrvJoeIBM4p1cVwTiki6mrqf+c1de/MnlJERETtoLS0FABgYWEBADhz5gxqa2vh5+cnlunbty969eqFjIwMAEBGRgbc3d3FhBQABAQEoKysDD/++KNY5tE66svU11FTU4MzZ86oldHT04Ofn59YhoiIiIhIGzjRORER6S7V/xZN1YWH/+vzKJlMBplM9uRdVSpERETg97//Pfr37w8AKCoqglQqhbm5uVpZGxsbFBUViWUeTUjVb6/f9qQyZWVlqKysxC+//IK6urpGy2RnZzfRaCIiIiKitsOeUkREpLMkgqDRBQAcHBxgZmYmLjExMU3GERoaiosXL2Lv3r1t3WQiIiIiok6DPaWIiIiaoaCgQG1cfFO9pObMmYMDBw7gxIkT6Nmzp7je1tYWNTU1KCkpUestVVxcDFtbW7HMb5+SV/90vkfL/PaJfcXFxVAoFDAyMoK+vj709fUbLVNfBxERERGRNrCnFBER6a42ePqeQqFQWx6XlBIEAXPmzEFiYiKOHTsGJycnte1eXl4wMDBASkqKuC4nJwf5+fnw8fEBAPj4+ODChQtqT8lLTk6GQqFAv379xDKP1lFfpr4OqVQKLy8vtTIqlQopKSliGSIiIiIibWBPKSIiojYQGhqKPXv24F//+hfkcrk4B5SZmRmMjIxgZmaGkJAQREZGwsLCAgqFAmFhYfDx8cGwYcMAAP7+/ujXrx+mTJmCNWvWoKioCAsXLkRoaKiYDJs5cyY2btyI+fPn480338SxY8eQkJCAgwcPirFERkYiODgYgwcPxtChQ7Fu3TpUVFRg2rRp7X9iiIiIiIj+h0kpIiLSXYLwcNFUXc2wefNmAICvr6/a+h07dmDq1KkAgE8//RR6enqYMGECqqurERAQgE2bNoll9fX1ceDAAcyaNQs+Pj4wMTFBcHAwli1bJpZxcnLCwYMHMXfuXKxfvx49e/ZEXFwcAgICxDKTJk3CrVu3EB0djaKiIgwaNAhHjhxpMPk50dOaOnUqSkpKsH///lbVI5FIkJiYiPHjx2skLiIiIupcmJQiIiKdJREeLpqqqzmEp0hiGRoaIjY2FrGxsY8t07t3bxw6dOiJ9fj6+uKHH354Ypk5c+Zgzpw5TcZE9DTWr1//VJ/xjs7X1xfHjx8H8HCoq6WlJTw9PTFt2jQEBQWplV2xYgUOHjwIpVIJqVSKkpISLURMRESkWzinFBEREVEnVFNTo7Vjm5mZqU3Qry2aOAczZsxAYWEhcnNz8eWXX6Jfv3549dVX8dZbbzU41iuvvIJZs2a1+phERET0EJNSRESku+qH72lqIdIiX19fzJkzBxEREbC0tERAQAAuXryIwMBAmJqawsbGBlOmTMHt27fV9gkLC0NERAS6d+8OGxsbbNu2TZxTTC6Xw9nZGYcPHxb3qaurQ0hICJycnGBkZARXV1esX79eLZapU6eqDbnz9fVFeHg45s+fDwsLC9ja2mLJkiVq+1y9ehUjRoyAoaEh+vXrh+Tk5AZtLCgowMSJE2Fubg4LCwuMGzcO169fb3DcFStWwN7eHq6urq07qQCMjY1ha2uLnj17YtiwYVi9ejW2bt2Kbdu24ejRo2K5pUuXYu7cuXB3d2/1MYmIiOghJqWIiIiIOoldu3ZBKpUiPT0dq1atwqhRo+Dh4YGsrCwcOXIExcXFmDhxYoN9LC0tcerUKYSFhWHWrFl45ZVXMHz4cJw9exb+/v6YMmUK7t+/D+Dh0xl79uyJffv24dKlS4iOjsYHH3yAhISEJmMzMTFBZmYm1qxZg2XLlomJJ5VKhaCgIEilUmRmZmLLli1YsGCB2v61tbUICAiAXC5HWloa0tPTYWpqitGjR6v1iEpJSUFOTg6Sk5Nx4MABTZzWBoKDg9G9e3d89dVXraqnuroaZWVlagsRERH9inNKERGRzpKoHi6aqotI2/r06YM1a9YAAJYvXw4PDw+sXLlS3L59+3Y4ODjgypUrcHFxAQAMHDgQCxcuBABERUVh1apVsLS0xIwZMwAA0dHR2Lx5M86fP49hw4bBwMAAS5cuFet0cnJCRkYGEhISGiS8HjVgwAAsXrxYjHPjxo1ISUnBiy++iKNHjyI7OxtJSUmwt7cHAKxcuRKBgYHi/vHx8VCpVIiLi4NEIgHw8MEA5ubmSE1Nhb+/PwDAxMQEcXFxkEqlrTuZT6CnpwcXFxe1XlotERMTo3YuiYiISB2TUkREpLu0+PQ9orbg5eUlvj537hy+/fZbmJqaNiiXm5srJqUGDBggrtfX10ePHj3UhqDVP4Xx5s2b4rrY2Fhs374d+fn5qKysRE1NDQYNGvTE2B49DgDY2dmJdV6+fBkODg5iQgoAfHx81MqfO3cO165dg1wuV1tfVVWF3Nxc8b27u3ubJqTqCYIgJsdaKioqCpGRkeL7srIyODg4tDY0IiIincGkFBEREVEnYWJiIr4uLy/H2LFjsXr16gbl7OzsxNcGBgZq2yQSidq6+sSLSvWwO+DevXsxb948rF27Fj4+PpDL5fj444+RmZn5xNgaO059nU+jvLwcXl5e2L17d4NtVlZW4utHz0Fbqaurw9WrVzFkyJBW1SOTySCTyTQUFRERke5hUoqIiHSX8L9FU3URdSCenp748ssv4ejoiG7dNHdLl56ejuHDh2P27Nniukd7KrWEm5sbCgoKUFhYKCbMTp48qVbG09MT8fHxsLa2hkKhaNXxWmvXrl345ZdfMGHCBK3GQUREpOs40TkRERFRJxQaGoq7d+/itddew+nTp5Gbm4ukpCRMmzYNdXV1La63T58+yMrKQlJSEq5cuYJFixbh9OnTrYrVz88PLi4uCA4Oxrlz55CWloYPP/xQrczkyZNhaWmJcePGIS0tDXl5eUhNTUV4eDhu3LjRquM/yf3791FUVIQbN27g5MmTWLBgAWbOnIlZs2Zh5MiRYrn8/HwolUrk5+ejrq4OSqUSSqUS5eXlbRYbERGRrmNSioiIdJZEEDS6EHUk9vb2SE9PR11dHfz9/eHu7o6IiAiYm5tDT6/lt3hvv/02goKCMGnSJHh7e+POnTtqvaZaQk9PD4mJiaisrMTQoUMxffp0rFixQq2MsbExTpw4gV69eiEoKAhubm4ICQlBVVVVm/ac2rZtG+zs7PDcc88hKCgIly5dQnx8PDZt2qRWLjo6Gh4eHli8eDHKy8vh4eEhPvmQiIiIWkYiCF3rLrusrAxmZmbwxTh0kxg0vQNRB6VnaKjtEIha7YFQg2NVCSgtLdXoH5313/UjvaLQrZtmflYePKjCt2diNB4rEXUd9d9NDhEJ0JMZazscakfXV43RdghERO2q/ndeU/fO7ClFRERERERERETtjhOdExGR7hIAPP3Dv5qui4g6lLS0NAQGBja6rbKyEkZGRo/dl3NBERERaR+TUkRERETUKQ0ePBhKpbLRbU0lpYiIiEj7mJQiIiKdpckJyjnROVHHY2RkBGdnZ22HQURERC3EpBQREekuAYCmkknMSRERERERaRQnOiciIiIiIiIionbHnlJERKS7BEGDPaXYVYqIiIiISJPYU4qIiIiIiIiIiNode0oREZHuUgGQaLAuIiIiIiLSGCaliIhIZ/Hpe0TUEV1cGgCFQqHtMIiIiLSOw/eIiIiIiIiIiKjdsacUERHpLk50TkRERETUYbGnFBERERERERERtTv2lCIiIt3FnlJERERERB0Wk1JERKS7mJQiIiIiIuqwOHyPiIiIiIiIiIjaHXtKERGR7lIBkGiwLiIiIiIi0hgmpYiIiIiI2lH/xUnQkxlrvN7rq8ZovE4iIqK2xKQUERHpLIkgQKKhuaA0VQ8RERERET3EpBQREekuTnRORERERNRhcaJzIiIiIiIiIiJqd+wpRUREukslABIN9XBSsacUEREREZEmsacUERERERERERG1O/aUIiIi3cU5pYiIiIiIOiwmpYiISIdpMCkFJqWIiIiIiDSJw/eIiIiIiIiIiKjdsacUERHpLg7fIyIiIiLqsNhTioiIiEjHTZ06FePHj291PRKJBPv37291PR3d9evXIZFIoFQqtR0KERGRTmNPKSIi0l0qARqbC0rFnlLUea1fvx4Ce/u1ikQiabDuiy++wKuvvqqFaIiIiHQDk1JERKS7BNXDRVN1EbVCTU0NpFKpVo5tZmamleP+ljbPQWOaG8+OHTswevRo8b25uXkbREVERNR1cPgeERERURvw9fXFnDlzEBERAUtLSwQEBODixYsIDAyEqakpbGxsMGXKFNy+fVttn7CwMERERKB79+6wsbHBtm3bUFFRgWnTpkEul8PZ2RmHDx8W96mrq0NISAicnJxgZGQEV1dXrF+/Xi2W3w7f8/X1RXh4OObPnw8LCwvY2tpiyZIlavtcvXoVI0aMgKGhIfr164fk5OQGbSwoKMDEiRNhbm4OCwsLjBs3DtevX29w3BUrVsDe3h6urq6tOqfV1dVYsGABHBwcIJPJ4OzsjL/+9a/NPg+/jefUqVPw8PCAoaEhBg8ejB9++KHR45ubm8PW1lZcDA0NW9UeIiKiro5JKSIi0l31E51raiFqpl27dkEqlSI9PR2rVq3CqFGj4OHhgaysLBw5cgTFxcWYOHFig30sLS1x6tQphIWFYdasWXjllVcwfPhwnD17Fv7+/pgyZQru378PAFCpVOjZsyf27duHS5cuITo6Gh988AESEhKajM3ExASZmZlYs2YNli1bJiaeVCoVgoKCIJVKkZmZiS1btmDBggVq+9fW1iIgIAByuRxpaWlIT0+HqakpRo8ejZqaGrFcSkoKcnJykJycjAMHDrTqfL7xxhv44osvsGHDBly+fBlbt26Fqalps87Db+MpLy/HSy+9hH79+uHMmTNYsmQJ5s2b1+jxQ0NDYWlpiaFDh2L79u1NDomsrq5GWVmZ2kJERES/6nLD9+pvHh6gVmPTjBBpg57AnDJ1fg+EWgDgXDeks/r06YM1a9YAAJYvXw4PDw+sXLlS3L59+3Y4ODjgypUrcHFxAQAMHDgQCxcuBABERUVh1apVsLS0xIwZMwAA0dHR2Lx5M86fP49hw4bBwMAAS5cuFet0cnJCRkYGEhISGiS8HjVgwAAsXrxYjHPjxo1ISUnBiy++iKNHjyI7OxtJSUmwt7cHAKxcuRKBgYHi/vHx8VCpVIiLixPnW9qxYwfMzc2RmpoKf39/AICJiQni4uJaPWzvypUrSEhIQHJyMvz8/AAAzz77rLj9ac/Db+P5/PPPoVKp8Ne//hWGhob43e9+hxs3bmDWrFlqx1+2bBlGjRoFY2NjfPPNN5g9ezbKy8sRHh7+2JhjYmLUYiIiIiJ1XS4pde/ePQDAdzik5UiIWqlK2wEQac69e/faZs4bTnROWubl5SW+PnfuHL799luxZ8+jcnNzxaTUgAEDxPX6+vro0aMH3N3dxXU2NjYAgJs3b4rrYmNjsX37duTn56OyshI1NTUYNGjQE2N79DgAYGdnJ9Z5+fJlODg4iAkpAPDx8VErf+7cOVy7dg1yuVxtfVVVFXJzc8X37u7uGplHSqlUQl9fH88///xjyzzNefhtPJcvX8aAAQPUhuL9tq0AsGjRIvG1h4cHKioq8PHHHz8xKRUVFYXIyEjxfVlZGRwcHJ7YTiIioq6kyyWl7O3tUVBQALlc3uhTVKj16m+4CgoKoFAotB0OUYvwc9w+BEHAvXv31P7w1fABNDfsjr25qAVMTEzE1+Xl5Rg7dixWr17doJydnZ342sDAQG2bRCJRW1d//6JSPZx8f+/evZg3bx7Wrl0LHx8fyOVyfPzxx8jMzHxibI0dp77Op1FeXg4vLy/s3r27wTYrKyvx9aPnoDWMjIyeuP1pz4Om4vH29sZHH32E6upqyGSyRsvIZLLHbiMiIqIumJTS09NDz549tR1Gl6BQKPjHPHV6/By3vY7yVDCitubp6Ykvv/wSjo6O6NZNc7dg6enpGD58OGbPni2ue7SnUku4ubmhoKAAhYWFYsLs5MmTamU8PT0RHx8Pa2vrdvmedHd3h0qlwvHjx8Xhe49q6Xlwc3PD3//+d1RVVYm9pX7b1sYolUp0796dSSciIqJW4KQ0RESkuwRocKJzbTeGOrvQ0FDcvXsXr732Gk6fPo3c3FwkJSVh2rRpqKura3G9ffr0QVZWFpKSknDlyhUsWrQIp0+fblWsfn5+cHFxQXBwMM6dO4e0tDR8+OGHamUmT54MS0tLjBs3DmlpacjLy0NqairCw8Nx48aNVh2/MY6OjggODsabb76J/fv3i8ern8i8pefh9ddfh0QiwYwZM3Dp0iUcOnQIf/nLX9TKfP3114iLi8PFixdx7do1bN68GStXrkRYWJjG20lERNSVMClFRES6i0/fow7E3t4e6enpqKurg7+/P9zd3REREQFzc3Po6bX8luztt99GUFAQJk2aBG9vb9y5c0ett1BL6OnpITExEZWVlRg6dCimT5+OFStWqJUxNjbGiRMn0KtXLwQFBcHNzQ0hISGoqqpqs55Tmzdvxssvv4zZs2ejb9++mDFjBioqKgC0/DyYmpri66+/xoULF+Dh4YEPP/ywwRBLAwMDxMbGwsfHB4MGDcLWrVvxySefiBPFExERUctIBD7yiDSsuroaMTExiIqKYpd26rT4Oe7cysrKYGZmBj/bt9BNr/UTLAPAA1UNjhZ9jtLSUg7pJKIWqf9ucohIgJ7MWOP1X181RuN1EhERtUT977ym7p273JxS1PZkMhmWLFmi7TCIWoWfYx2hUgF4+ombm66LiIiIiIg0hUkpIiIiImoXaWlpCAwMbHRbZWXlE5+wV15e3lZhERERkZYwKUVERLpLk3NBcbQ7UasNHjwYSqWy0W1NJaWIiIhI9zApRUREuotJKaIOxcjICM7OztoOg4iIiDoIPn2PiIiIiIiIiIjaHZNS1CKxsbFwdHSEoaEhvL29cerUqSeW37dvH/r27QtDQ0O4u7vj0KFD7RQpUeNOnDiBsWPHwt7eHhKJBPv3729yn9TUVHh6ekImk8HZ2Rk7d+5s8ziplVSCZhciIiIiItIYJqWo2eLj4xEZGYnFixfj7NmzGDhwIAICAnDz5s1Gy3///fd47bXXEBISgh9++AHjx4/H+PHjcfHixXaOnOhXFRUVGDhwIGJjY5+qfF5eHsaMGYORI0dCqVQiIiIC06dPR1JSUhtHSkREREREpJskgsBJMqh5vL29MWTIEGzcuBEAoFKp4ODggLCwMLz//vsNyk+aNAkVFRU4cOCAuG7YsGEYNGgQtmzZ0m5xEz2ORCJBYmIixo8f/9gyCxYswMGDB9WSqa+++ipKSkpw5MiRdoiSmqOsrAxmZmZ4oXswuulJNVLnA1UNUn7ZhdLSUigUCo3USURdS/13k0NEAvRkxhqv//qqMRqvk4iIqCXqf+c1de/MnlLULDU1NThz5gz8/PzEdXp6evDz80NGRkaj+2RkZKiVB4CAgIDHlifqiPg57qQEDQ7d4//hEBERERFpFJ++R81y+/Zt1NXVwcbGRm29jY0NsrOzG92nqKio0fJFRUVtFieRpj3uc1xWVsbHmBMRUbNcXBrAHpdERERgUoqIiHSZIADQUA8n9pQiIiIiItIoDt+jZrG0tIS+vj6Ki4vV1hcXF8PW1rbRfWxtbZtVnqgjetznWKFQsJcUERERERFRCzApRc0ilUrh5eWFlJQUcZ1KpUJKSgp8fHwa3cfHx0etPAAkJyc/tjxRR8TPcSelUml2ISIiIiIijWFSipotMjIS27Ztw65du3D58mXMmjULFRUVmDZtGgDgjTfeQFRUlFj+nXfewZEjR7B27VpkZ2djyZIlyMrKwpw5c7TVBCKUl5dDqVRCqVQCAPLy8qBUKpGfnw8AiIqKwhtvvCGWnzlzJn766SfMnz8f2dnZ2LRpExISEjB37lxthE9PSxA0uxARERERkcZwTilqtkmTJuHWrVuIjo5GUVERBg0ahCNHjoiTQOfn50NP79d85/Dhw7Fnzx4sXLgQH3zwAfr06YP9+/ejf//+2moCEbKysjBy5EjxfWRkJAAgODgYO3fuRGFhoZigAgAnJyccPHgQc+fOxfr169GzZ0/ExcUhICCg3WMnIiIiIiLSBRJB4H/9EhGRbikrK4OZmRlGGb+KbhKpRup8INTg2P29KC0t5VOziKhF6r+b+D1CRES67ml/53H4HhERERERERERtTsO3yMiIt0lCAA01CGYHYuJiIiIiDSKSSkiItJdKgGQMClFRERERNQRcfgeERERERERERG1O/aUIiIi3SUIAFQarIuIiIiIiDSFPaWIiIiIiIiIiKjdsacUERHpLEElQNDQnFICe0oREREREWkUk1JERKS7BBU0N3xPQ/UQEREREREADt8jalNTp07F+PHjxfe+vr6IiIho9zhSU1MhkUhQUlLy2DISiQT79+9/6jqXLFmCQYMGtSqu69evQyKRQKlUtqoeIiIiIiIi6nyYlKIuZ+rUqZBIJJBIJJBKpXB2dsayZcvw4MGDNj/2V199hY8++uipyj5NIomInkxQCRpdiIiIiIhIczh8j7qk0aNHY8eOHaiursahQ4cQGhoKAwMDREVFNShbU1MDqVSqkeNaWFhopB4iIiIiIiKizo5JKeqSZDIZbG1tAQCzZs1CYmIi/v3vfyMqKgpTp05FSUkJhgwZgtjYWMhkMuTl5aGgoADvvvsuvvnmG+jp6eGPf/wj1q9fD0dHRwBAXV0d3nvvPWzfvh36+voICQlpMDGyr68vBg0ahHXr1gEAqqurER0djT179uDmzZtwcHBAVFQUXnjhBYwcORIA0L17dwBAcHAwdu7cCZVKhdWrV+Pzzz9HUVERXFxcsGjRIrz88svicQ4dOoSIiAgUFBRg2LBhCA4ObvY5WrBgARITE3Hjxg3Y2tpi8uTJiI6OhoGBgVq5rVu3Yvny5bhz5w5eeuklbNu2DWZmZuL2uLg4rF27Fnl5eXB0dER4eDhmz57d7HiIWuKBUK2xuaAeoFYj9RBR11V/X1BWVqblSIiIiNpW/e+6ph4WxKQUEQAjIyPcuXNHfJ+SkgKFQoHk5GQAQG1tLQICAuDj44O0tDR069YNy5cvx+jRo3H+/HlIpVKsXbsWO3fuxPbt2+Hm5oa1a9ciMTERo0aNeuxx33jjDWRkZGDDhg0YOHAg8vLycPv2bTg4OODLL7/EhAkTkJOTA4VCASMjIwBATEwM/vGPf2DLli3o06cPTpw4gf/7v/+DlZUVnn/+eRQUFCAoKAihoaF46623kJWVhXfffbfZ50Qul2Pnzp2wt7fHhQsXMGPGDMjlcsyfP18sc+3aNSQkJODrr79GWVkZQkJCMHv2bOzevRsAsHv3bkRHR2Pjxo3w8PDADz/8gBkzZsDExKRFiTKipyWVSmFra4vvig5ptF5bW1uN9Zwkoq6n/l7DwcFBy5EQERG1j3v37ql1WvgtJqWoSxMEASkpKUhKSkJYWJi43sTEBHFxceIfn//4xz+gUqkQFxcHiUQCANixYwfMzc2RmpoKf39/rFu3DlFRUQgKCgIAbNmyBUlJSY899pUrV5CQkIDk5GT4+fkBAJ599llxe/1QP2tra5ibmwN42LNq5cqVOHr0KHx8fMR9vvvuO2zduhXPP/88Nm/ejOeeew5r164FALi6uuLChQtYvXp1s87NwoULxdeOjo6YN28e9u7dq5aUqqqqwt/+9jc888wzAIDPPvsMY8aMwdq1a2Fra4vFixdj7dq14jlxcnLCpUuXsHXrVialqE0ZGhoiLy8PNTU1Gq1XKpXC0NBQo3USUddR/7s9Pz//iTfonVlZWRkcHBxQUFAAhUKh7XDaRFdoI9A12sk26o6u0M7O1kZBEHDv3j3Y29s/sRyTUtQlHThwAKampqitrYVKpcLrr7+OJUuWiNvd3d3VekOcO3cO165dg1wuV6unqqoKubm5KC0tRWFhIby9vcVt3bp1w+DBgx/bXVGpVEJfXx/PP//8U8d97do13L9/Hy+++KLa+pqaGnh4eAAALl++rBYHADGB1Rzx8fHYsGEDcnNzUV5ejgcPHjT48uvVq5eYkKo/jkqlQk5ODuRyOXJzcxESEoIZM2aIZR48eKCzN+LUsRgaGjKBREQdip7ew2cMmZmZdYo/KFpDoVCwjTqiK7STbdQdXaGdnamNT/N3H5NS1CWNHDkSmzdvhlQqhb29Pbp1U/9RMDExUXtfXl4OLy8vcVjao6ysrFoUQ/1wvOYoLy8HABw8eFAtGQQ8nCdLUzIyMjB58mQsXboUAQEBMDMzw969e8XeV82Jddu2bQ2SZPr6+hqLlYiIiIiIiDonJqWoSzIxMYGzs/NTl/f09ER8fDysra0fm5W2s7NDZmYmRowYAeBhj6AzZ87A09Oz0fLu7u5QqVQ4fvy4OHzvUfU9terq6sR1/fr1g0wmQ35+/mN7WLm5ueHf//632rqTJ0823chHfP/99+jduzc+/PBDcd1//vOfBuXy8/Px888/i10yT548CT09Pbi6usLGxgb29vb46aefMHny5GYdn4iIiIiIiHSfnrYDIOoMJk+eDEtLS4wbNw5paWnIy8tDamoqwsPDcePGDQDAO++8g1WrVmH//v3Izs7G7NmzUVJS8tg6HR0dERwcjDfffBP79+8X60xISAAA9O7dGxKJBAcOHMCtW7dQXl4OuVyOefPmYe7cudi1axdyc3Nx9uxZfPbZZ9i1axcAYObMmbh69Sree+895OTkYM+ePdi5c2ez2tunTx/k5+dj7969yM3NxYYNG5CYmNignKGhIYKDg3Hu3DmkpaUhPDwcEydOFJ9suHTpUsTExGDDhg24cuUKLly4gB07duCTTz5pVjxERES6QCaTYfHixRrt3dzRsI26oyu0k23UHV2hnTrbRoGoiwkODhbGjRvX7O2FhYXCG2+8IVhaWgoymUx49tlnhRkzZgilpaWCIAhCbW2t8M477wgKhUIwNzcXIiMjhTfeeEOtrueff1545513xPeVlZXC3LlzBTs7O0EqlQrOzs7C9u3bxe3Lli0TbG1tBYlEIgQHBwuCIAgqlUpYt26d4OrqKhgYGAhWVlZCQECAcPz4cXG/r7/+WnB2dhZkMpnwxz/+Udi+fbsAQPjll18e224AQmJiovj+vffeE3r06CGYmpoKkyZNEj799FPBzMxM3L548WJh4MCBwqZNmwR7e3vB0NBQePnll4W7d++q1bt7925h0KBBglQqFbp37y6MGDFC+OqrrwRBEIS8vDwBgPDDDz88Ni4iIiIiIiLSTRJBeMwszERERERERERERG2Ew/eIiIiIiIiIiKjdMSlFRERERERERETtjkkpIiIiIiIiIiJqd0xKERERERG1sdjYWDg6OsLQ0BDe3t44deqUtkPSqCVLlkAikagtffv21XZYrXLixAmMHTsW9vb2kEgk2L9/v9p2QRAQHR0NOzs7GBkZwc/PD1evXtVOsC3UVBunTp3a4LqOHj1aO8G2UExMDIYMGQK5XA5ra2uMHz8eOTk5amWqqqoQGhqKHj16wNTUFBMmTEBxcbGWIm6Zp2mnr69vg+s5c+ZMLUXcfJs3b8aAAQOgUCigUCjg4+ODw4cPi9t14To21cbOfg0bw6QUEREREVEbio+PR2RkJBYvXoyzZ89i4MCBCAgIwM2bN7Udmkb97ne/Q2Fhobh899132g6pVSoqKjBw4EDExsY2un3NmjXYsGEDtmzZgszMTJiYmCAgIABVVVXtHGnLNdVGABg9erTadf3iiy/aMcLWO378OEJDQ3Hy5EkkJyejtrYW/v7+qKioEMvMnTsXX3/9Nfbt24fjx4/j559/RlBQkBajbr6naScAzJgxQ+16rlmzRksRN1/Pnj2xatUqnDlzBllZWRg1ahTGjRuHH3/8EYBuXMem2gh07mvYGD59j4iIiIioDXl7e2PIkCHYuHEjAEClUsHBwQFhYWF4//33tRydZixZsgT79++HUqnUdihtQiKRIDExEePHjwfwsJeUvb093n33XcybNw8AUFpaChsbG+zcuROvvvqqFqNtmd+2EXjYU6qkpKRBD6rO7NatW7C2tsbx48cxYsQIlJaWwsrKCnv27MHLL78MAMjOzoabmxsyMjIwbNgwLUfcMr9tJ/Cwl82gQYOwbt067QanQRYWFvj444/x8ssv6+R1BH5tY0hIiE5eQ/aUIiIiIiJqIzU1NThz5gz8/PzEdXp6evDz80NGRoYWI9O8q1evwt7eHs8++ywmT56M/Px8bYfUZvLy8lBUVKR2Xc3MzODt7a1z1zU1NRXW1tZwdXXFrFmzcOfOHW2H1CqlpaUAHv6hDwBnzpxBbW2t2rXs27cvevXq1amv5W/bWW/37t2wtLRE//79ERUVhfv372sjvFarq6vD3r17UVFRAR8fH528jr9tYz1duYb1umk7ACIiIiIiXXX79m3U1dXBxsZGbb2NjQ2ys7O1FJXmeXt7Y+fOnXB1dUVhYSGWLl2KP/7xj7h48SLkcrm2w9O4oqIiAGj0utZv0wWjR49GUFAQnJyckJubiw8++ACBgYHIyMiAvr6+tsNrNpVKhYiICPz+979H//79ATy8llKpFObm5mplO/O1bKydAPD666+jd+/esLe3x/nz57FgwQLk5OTgq6++0mK0zXPhwgX4+PigqqoKpqamSExMRL9+/aBUKnXmOj6ujYBuXMPfYlKKiIiIiIhaJTAwUHw9YMAAeHt7o3fv3khISEBISIgWI6PWeHQYoru7OwYMGIDnnnsOqampeOGFF7QYWcuEhobi4sWLnX6+s6Y8rp1vvfWW+Nrd3R12dnZ44YUXkJubi+eee669w2wRV1dXKJVKlJaW4p///CeCg4Nx/PhxbYelUY9rY79+/XTiGv4Wh+8REREREbURS0tL6OvrN3gCVHFxMWxtbbUUVdszNzeHi4sLrl27pu1Q2kT9tetq1/XZZ5+FpaVlp7yuc+bMwYEDB/Dtt9+iZ8+e4npbW1vU1NSgpKRErXxnvZaPa2djvL29AaBTXU+pVApnZ2d4eXkhJiYGAwcOxPr163XqOj6ujY3pjNfwt5iUIiIiIiJqI1KpFF5eXkhJSRHXqVQqpKSkqM0RomvKy8uRm5sLOzs7bYfSJpycnGBra6t2XcvKypCZmanT1/XGjRu4c+dOp7qugiBgzpw5SExMxLFjx+Dk5KS23cvLCwYGBmrXMicnB/n5+Z3qWjbVzsbUP5igM13P31KpVKiurtaZ69iY+jY2RheuIYfvERERERG1ocjISAQHB2Pw4MEYOnQo1q1bh4qKCkybNk3boWnMvHnzMHbsWPTu3Rs///wzFi9eDH19fbz22mvaDq3FysvL1Xof5OXlQalUwsLCAr169UJERASWL1+OPn36wMnJCYsWLYK9vb3a0+s6uie10cLCAkuXLsWECRNga2uL3NxczJ8/H87OzggICNBi1M0TGhqKPXv24F//+hfkcrk4v5CZmRmMjIxgZmaGkJAQREZGwsLCAgqFAmFhYfDx8elUT2xrqp25ubnYs2cP/vSnP6FHjx44f/485s6dixEjRmDAgAFajv7pREVFITAwEL169cK9e/ewZ88epKamIikpSWeu45PaqAvXsFECERERERG1qc8++0zo1auXIJVKhaFDhwonT57UdkgaNWnSJMHOzk6QSqXCM888I0yaNEm4du2atsNqlW+//VYA0GAJDg4WBEEQVCqVsGjRIsHGxkaQyWTCCy+8IOTk5Gg36GZ6Uhvv378v+Pv7C1ZWVoKBgYHQu3dvYcaMGUJRUZG2w26WxtoHQNixY4dYprKyUpg9e7bQvXt3wdjYWPjzn/8sFBYWai/oFmiqnfn5+cKIESMECwsLQSaTCc7OzsJ7770nlJaWajfwZnjzzTeF3r17C1KpVLCyshJeeOEF4ZtvvhG368J1fFIbdeEaNkYiCILQnkkwIiIiIiIiIiIizilFRERERERERETtjkkpIiIiIiIiIiJqd0xKERERERERERFRu2NSioiIiIiIiIiI2h2TUkRERERERERE1O6YlCIiIiIiIiIionbHpBQREREREREREbU7JqWIiIiIiIiIiKjdMSlFRERERERERETtjkkpIiIiIiIiIiJqd0xKERERERERERFRu2NSioiIiIiIiIiI2t3/BxQLBycmP9fRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LightGBM Results:\n",
            "ROC-AUC: 0.9129\n",
            "PR-AUC: 0.5578\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.86      0.92    113866\n",
            "         1.0       0.18      0.81      0.30      4242\n",
            "\n",
            "    accuracy                           0.86    118108\n",
            "   macro avg       0.59      0.84      0.61    118108\n",
            "weighted avg       0.96      0.86      0.90    118108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results_light_balanced = pipeline_balanced.run_pipeline(\n",
        "    models_to_run=[\n",
        "        'LightGBM'\n",
        "    ],\n",
        "    selected_features=features\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec420c45",
      "metadata": {
        "id": "ec420c45"
      },
      "source": [
        "Dense Neural Network Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "639d8431",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "639d8431",
        "outputId": "9b4238c0-c2d6-480c-f7dc-a920ab732a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-15 09:15:09,670 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'early_stop': True, 'patience': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing DenseNN ===\n",
            "Tuning DenseNN hyperparameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best: 100%|██████████|10/10, best_cost=-0.873\n",
            "2025-04-15 09:27:25,271 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.8729454894106151, best pos: [5.60178584e-03 2.10971752e+02 1.44448134e+02 3.59488858e-01\n",
            " 1.51780116e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized Dense NN Parameters:\n",
            "{'learning_rate': np.float64(0.005601785837764509), 'layer1': 210, 'layer2': 144, 'dropout_rate': np.float64(0.15178011585806242)}\n",
            "Best ROC-AUC: 0.8729\n",
            "Training DenseNN with optimized parameters...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DenseNN Results:\n",
            "ROC-AUC: 0.7548\n",
            "PR-AUC: 0.1599\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.44      0.60    113866\n",
            "         1.0       0.05      0.85      0.10      4242\n",
            "\n",
            "    accuracy                           0.45    118108\n",
            "   macro avg       0.52      0.64      0.35    118108\n",
            "weighted avg       0.95      0.45      0.59    118108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results_dnn_balanced = pipeline_balanced.run_pipeline(\n",
        "    models_to_run=[\n",
        "        'DenseNN'\n",
        "    ],\n",
        "    selected_features=features\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}